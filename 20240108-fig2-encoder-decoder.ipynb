{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"import pickle\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.stats import wilcoxon as wilcoxon\nfrom matplotlib.ticker import AutoMinorLocator, MultipleLocator\n\n# meta analysis functions\nimport sys\nsys.path.append('/code/')\nfrom util import analysis\nfrom util import plotting\nfrom util import util_continuous as utils\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"PATH = '/data/'"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"\nwith open(PATH + 'encoder-estimation-data/encoder-decoder-data.pickle', 'rb') as handle:\n    encoder, encoder_r2, idx_dict, pos_vel_model, pos, dec_vels, decoders = pickle.load(handle)\n\nkeys = ['METACPHS_S106', 'METACPHS_S107','METACPHS_S108', 'METACPHS_S109', 'METACPHS_S110', 'METACPHS_S111', 'METACPHS_S112', 'METACPHS_S113', 'METACPHS_S114', 'METACPHS_S115', 'METACPHS_S116', 'METACPHS_S117', 'METACPHS_S118', 'METACPHS_S119']\n\n\nwith open(PATH + 'trial-related-data/times-decoder-update.pickle','rb') as handle:\n    update_ix, update_times = pickle.load(handle)\n# load the order of the trials in terms of when the subject saw the trial\nwith open(PATH + 'trial-related-data/decoder_trials_in_order.pickle','rb') as handle:\n    trials_list, conds_trial_list = pickle.load(handle)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# check the encoder shape to match as expected\nassert(encoder.shape == (utils.n_blocks, utils.n_keys, utils.n_conds, len(update_ix) - 2, utils.n_ch, 9))"},{"cell_type":"markdown","metadata":{},"source":"set up the figure"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# check the encoder shape to match as expected\nassert(encoder.shape == (utils.n_blocks, utils.n_keys, utils.n_conds, len(update_ix) - 2, utils.n_ch, 9))"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"import matplotlib.ticker as ticker\n\nlabel_size = 6\n## SETUP THE FIGURE HERE\n## HAVE TO RE-REUN FROM HERE TO \"CLEAR\" THE PLOT\nfig_encdec = plt.figure(figsize = (6.5, 5.5), layout='constrained') # set the total figure size\nmosaic = \"\"\"\n    aabb.eeff\n    ccdd.gghh\n    .........\n    iijj.mmnn\n    kkll.oopp\n    qqqqrrsss\n    qqqqrrsss\n    \"\"\"\n\n# this is [ 0,0; 0,1]\n#         [ 1,0; 1,1]\n\n# set up the axes\nax_dict = fig_encdec.subplot_mosaic(mosaic)\nfor ii in ax_dict:\n    plotting.remove_and_set_axes(ax_dict[ii], bottom=True, left=True)\n    ax_dict[ii].tick_params(axis='both', which='major', labelsize = label_size)\n    ax_dict[ii].tick_params(axis='both', which='minor', labelsize = label_size)\n    # set the x-ticks at multiples of 1\n    ax_dict[ii].xaxis.set_major_locator(ticker.MultipleLocator(base=5))\n    ax_dict[ii].xaxis.set_minor_locator(ticker.MultipleLocator(base=1))\nfig_encdec.patch.set_facecolor('white')\n\n\nax_dict['a'].set_title(\"$D \\cdot F_0$\")\n\n\nax_dict['a'].set_ylabel(\"(0, 0)\")\nax_dict['b'].set_ylabel(\"(0, 1)\")\nax_dict['c'].set_ylabel(\"(1, 0)\")\nax_dict['d'].set_ylabel(\"(1, 1)\")\n\nax_dict['e'].set_title(\"$D \\cdot F_1$\")\n\nax_dict['e'].set_ylabel(\"(0, 0)\")\nax_dict['f'].set_ylabel(\"(0, 1)\")\nax_dict['g'].set_ylabel(\"(1, 0)\")\nax_dict['h'].set_ylabel(\"(1, 1)\")\n\nax_dict['i'].set_title(\"$D \\cdot B_0$\")\n\nax_dict['i'].set_ylabel(\"(0, 0)\")\nax_dict['j'].set_ylabel(\"(0, 1)\")\nax_dict['k'].set_ylabel(\"(1, 0)\")\nax_dict['l'].set_ylabel(\"(1, 1)\")\n\nax_dict['m'].set_title(\"$D \\cdot B_1$\")\n\nax_dict['m'].set_ylabel(\"(0, 0)\")\nax_dict['n'].set_ylabel(\"(0, 1)\")\nax_dict['o'].set_ylabel(\"(1, 0)\")\nax_dict['p'].set_ylabel(\"(1, 1)\")\n\nax_dict['q'].set_xlabel(\"Across Trials\")\nax_dict['q'].set_ylabel(r'$|E_f - E_i|_F$')\n\nax_dict['s'].set_xlabel(\"Time (min)\")\nax_dict['s'].set_ylabel(r'$|E_{t+1} - E_t|_F$')\n"},{"cell_type":"markdown","metadata":{},"source":"Table of variables used \n\n| Variable | Shape | Shape Representations | Meaning |\n| --- | --- | --- | --- |\n| encoder_linear | (2, 14, 8, 17, 64, 8) | blocks x subjects x conditions x number of updates x number of channels x number of encoder features | the encoder estimations of each user and each trial without the affine term |\n|enc_all_min1 - 5 | (2, 14, 8, 64, 8) | blocks x subjects x conditions x number of channels x number of encoder features | the encoder estimations of each user and each trial averaged per minute of trial to dampen the overfitting that might have happened |\n| enc_all_diff | (4, 2, 14, 8) | interval between minutes in 5-minute trial x blocks x subjects x conditions | the frobenious norm of the difference between each minute-averaged encoder = fro norm(E_{t+1} - E_{t}) |\n| enc_all_fi | (2, 14, 8)| last minute - first minute (1) x blocks x subjects x conditions | the frobenious norm of the difference between the first and last-averaged encoder = fro norm(E_{final} - E_{inital}) |\n| enc_all_diff_subj | (14, ) | subjects | mean of enc_all_diff per subject |\n| enc_fi_diff_subj | (14, ) | subjects | mean of enc_fi_diff per subject |\n\n\n\nExplanations of shapes:\n* number of blocks = 2 -- experimental setup\n* numebr of subject = 14 -- experimental setup\n* number of conditions = 8 -- experimental setup of decoder conditions\n* number of updates = 17 -- this is the number of decoder updates - 2 (why -2? because we have to take the sifference between updates and the last one was cut short)\n* number of channels = 64 -- the number of emg channels and the number of channels used for the decoder, so can keep the multiplication\n* number of features = 8 -- the encoder has 8 features and 1 affine term; the feature are: target position (x, y), target velocity (x, y), position error (x, y), velocity error (x, y)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"## this code sets up the encoder variables to be plotted and compared in this notebook\n\n## set up variables to use for this code\n# number of features of the encoder\n# 8 features of the encoder = target position (x, y), target velocity (x, y), position error (x, y), velocity error (x, y)\nn_feat = 8 \n\n## take the encoder variables without the affine term \n# this is done because the affine term was to fit the encoder, but does not represent any encoding of the user\nencoder_linear = encoder[:, :, :, :, :, :-1]\n# check that encoder_linear variable is the right shape -- same as the encoder, but the last axis should be the number of features\nassert(encoder_linear.shape == (utils.n_blocks, utils.n_keys, utils.n_conds, len(update_ix) - 2, utils.n_ch, n_feat))\n\n## average the encoder across minute to use the minute-averaged encoder as a measurement of the user\n# this averaging is done so that we can reduce the overfitting of the encoder to the 20-second intervals\naxis_time = 3 # the time axis is the 4th one, so = 3\nenc_all_min1 = np.mean(encoder_linear[:, :, :, 1:4], axis = axis_time) # average across the first minute\nenc_all_min2 = np.mean(encoder_linear[:, :, :, 4:7], axis = axis_time) # average across the 2nd minute\nenc_all_min3 = np.mean(encoder_linear[:, :, :, 7:10], axis = axis_time) # average across the 3rd minute\nenc_all_min4 = np.mean(encoder_linear[:, :, :, 10:13], axis = axis_time) # average across the 4th minute\nenc_all_min5 = np.mean(encoder_linear[:, :, :, -3:], axis = axis_time) # average across the last minute\nassert(enc_all_min1.shape == enc_all_min2.shape == enc_all_min3.shape \n       == enc_all_min4.shape == enc_all_min5.shape \n       == (utils.n_blocks, utils.n_keys, utils.n_conds, utils.n_ch, n_feat))\n\n# stack the minute-averaged encoders together so we can find the change in the users' encoders minute to minute\nenc_all_min = np.stack((enc_all_min1, enc_all_min2, enc_all_min3, enc_all_min4, enc_all_min5))\n# 5 in the first axis since we're stacking 5 arrays together\nassert(enc_all_min.shape == (5, utils.n_blocks, utils.n_keys, utils.n_conds, utils.n_ch,  n_feat))\n\n## subtract the difference in the encoder from minute to minute and then take the frobenious norm of that difference\n# this is |E_t+1 - E_t|_F\nenc_all_diff = np.linalg.norm(np.diff(enc_all_min, axis = 0), axis = (-1, -2))\n# this is |E_final - E_initial|_F\nenc_all_fi = np.linalg.norm(enc_all_min5 - enc_all_min1, axis = (-1, -2))\n\n# find the mean difference per subject\nenc_all_diff_subj = np.mean(enc_all_diff, axis = (0, 1, 3))\nenc_fi_diff_subj = np.mean(enc_all_fi, axis = (0, 2))\nassert(enc_all_diff_subj.shape == enc_fi_diff_subj.shape == (utils.n_keys, ))"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"enc_all_fi.shape"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"data1 = np.ndarray.flatten(enc_fi_diff_subj)\ndata2 = np.ndarray.flatten(enc_all_diff_subj)\ndata1.shape"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# fig,ax = plt.subplots(1,1,figsize=(3, 5))\nfig_ax = ax_dict['r']\n\ndata1 = np.ndarray.flatten(enc_fi_diff_subj)\ndata2 = np.ndarray.flatten(enc_all_diff_subj)\nassert(data1.shape == data2.shape == (utils.n_keys,))\ndata_groups = [data1, data2]\ndata_labels = ['$|E_f-E_i|$', '$|E_{t+1} - E_t|$']\ndata_pos = [0, 0.4]\n\nbplot = fig_ax.boxplot(data_groups, \n                    showfliers=False,\n                    patch_artist=True,\n                    positions=data_pos,\n                    widths = 0.3,\n                    boxprops=dict(edgecolor=\"white\", alpha=0.5),\n                    medianprops=dict(color='k', lw=0.5))\n\n\nfor patch, color in zip(bplot['boxes'], [utils.colors['E'], utils.colors['E']]):\n    patch.set_facecolor(color)\n\n\n# rotate labels  \nfig_ax.set_xticks(data_pos,data_labels, rotation=0)\nw = wilcoxon(data1, data2) \nprint(w)\n\nplotting.plot_significance(pvalue = w.pvalue, data1=data1, data2 = data2, data_pos = data_pos, \n                  fig=fig_encdec, ax=fig_ax, fontsize=10, lw=0.5, y_asterix=0.6, y_bar=0.5)\n\nfig_encdec"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"enc_change_across_trials = np.zeros((utils.n_blocks, utils.n_keys, utils.n_conds))\ntrial_label = np.zeros((utils.n_blocks, utils.n_keys, utils.n_conds))\nx_ticks = np.arange(1, 17, 1)  # Ticks for every integer from 0 to 14\nf, ax = plt.subplots(utils.n_keys, 1, figsize=(2, 10), layout = 'constrained')\nfor iK in range(utils.n_keys):\n    # x_ticks = np.arange(1, 17, 1)  # Ticks for every integer from 0 to 14\n    # block 1\n    iB = 0\n    # for iC in conds_trial_list[iB, iK]:\n    enc_diff_trial = (np.linalg.norm(enc_all_min5[iB, iK, conds_trial_list[iB, iK]] - enc_all_min1[iB, iK, conds_trial_list[iB, iK]], axis = (-1, -2)))\n                    #   /np.linalg.norm(enc_all_init[iB, iK, conds_trial_list[iB, iK]], axis = (-1, -2)))\n    enc_change_across_trials[iB, iK, :] = enc_diff_trial\n    # ax[iK].plot(x_ticks[:8], enc_all_mean[iB, iK, conds_trial_list[iB, iK]], color = 'blue')\n    iB = 1\n    enc_diff_trial = (np.linalg.norm(enc_all_min5[iB, iK, conds_trial_list[iB, iK]] - enc_all_min1[iB, iK, conds_trial_list[iB, iK]], axis = (-1, -2)))\n                        # /np.linalg.norm(enc_all_init[iB, iK, conds_trial_list[iB, iK]], axis = (-1, -2)))\n    enc_change_across_trials[iB, iK, :] = enc_diff_trial\n    data_to_plot = np.append(enc_change_across_trials[0, iK], enc_change_across_trials[1, iK])\n    \n    ax[iK].plot(x_ticks, data_to_plot, '-o', color = utils.colors['E'], ms = 1, lw = 1)\n    # ax[iK].plot(x_ticks[8:], enc_all_mean[iB, iK, conds_trial_list[iB, iK]], color = 'blue')\n\n    # ax[iK].plot(np.linspace(9, 16, 8), enc_change_across_trials[1, iK], '-o', color = 'darkgray')\n    # Set x-axis ticks and labels\n    x_labels = [str(i) if i % 2 == 0 else \"\" for i in x_ticks]  # Labels for even integers, empty string for odd ones\n    ax[iK].set_xticks(x_ticks, x_labels, fontsize = 4)\n    # ax[iK].vlines(x = 8, ymin=-0.5, ymax = max(data_to_plot), zorder = 0)\n\n    # # y-axis\n    ax[iK].set_ylabel(r'$|E_f - E_i|_F$', fontsize = 4)\n    ax[iK].set_title(keys[iK], fontsize = 4)\n    enc_mean = np.mean(enc_all_diff[:, :, iK].flatten())\n    enc_std = np.std(enc_all_diff[:, :, iK].flatten())\n    ax[iK].hlines(y = enc_mean, xmin = 1, xmax = 16, zorder = 0, ls = '--', lw = 1)\n    # ax[iK].hlines(y = enc_null_std[iK], xmin = 0, xmax = 16, zorder = 0)\n    ax[iK].fill_between(x_ticks, y1 = enc_mean - enc_std, \n                        y2 = enc_mean + enc_std, alpha = 0.2, color = utils.colors['E'])\n    ax[iK].tick_params(axis='both', which='major', labelsize = label_size)\n    ax[iK].tick_params(axis='both', which='minor', labelsize = label_size)\n    # plt.show()\n\n# f.set_size_inches(6, 15)"},{"cell_type":"markdown","metadata":{},"source":"Encoder-Decoder Pairs"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"enc_dim = encoder[:, :, :, :, :, idx_dict['targ_pos_idx']] # use reference only\nenc_dim.shape\nt_upd = update_times[1:-1]"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# target position contribution\n# D * F0\nenc_dim = encoder_linear[:, :, :, :, :, idx_dict['targ_pos_idx']] # use reference only\n\n# calculate the decoder-encoder pairs here\nenc_dec = np.zeros((utils.n_blocks, utils.n_keys, utils.n_conds, len(update_ix) - 2, 2, 2))\nenc_dec_control = np.zeros_like((enc_dec))\n\n## takes a long time to run!\nfor iK, key in enumerate(keys):\n    # block 1\n    b = 0\n    dec1 = decoders[b, iK][:, 1:-1]\n    enc1 = enc_dim[b, iK] # [:, np.newaxis]\n    enc_dec[b, iK] = dec1@enc1\n\n    # # control - mean of each user's encoder\n    # # assume the encoder of each user did not change across blocks, conditions, or within trial\n    # enc_cont_subj = enc_control[iK]\n    # enc_dec_control[b, iK] = dec1@enc_cont_subj\n    \n    # block 1\n    b = 1\n    dec2 = decoders[b, iK][:, 1:-1]\n    enc2 = enc_dim[b, iK] #[:, np.newaxis]\n    enc_dec[b, iK] = dec2@enc2\n\n    # # control - mean of each user's encoder\n    # enc_dec_control[b, iK] = dec2@enc_cont_subj\n\ned_all = np.mean(enc_dec, axis = (0, 2))\ned_all_control = np.mean(enc_dec_control, axis = (0, 2))\n\n# ld_low\n# [a  b]\n# [c  d]\nplotting.plot_time_domain(t_upd/60, ed_all[:, :, 0, 0], axis = 0, ax=ax_dict['a'], \n                          color = utils.colors['FF'], ls='-o', alpha = 0.1, lw=1, ms = 2, remove_axes=False)\nplotting.plot_time_domain(t_upd/60, ed_all[:, :, 0, 1], axis = 0, ax=ax_dict['b'], \n                          color = utils.colors['FF'], ls='-o', alpha = 0.1, lw=1, ms = 2, remove_axes=False)\nplotting.plot_time_domain(t_upd/60, ed_all[:, :, 1, 0], axis = 0, ax=ax_dict['c'],\n                          color = utils.colors['FF'], ls='-o', alpha = 0.1, lw=1, ms = 2, remove_axes=False)\nplotting.plot_time_domain(t_upd/60, ed_all[:, :, 1, 1], axis = 0, ax=ax_dict['d'], \n                          color = utils.colors['FF'], ls='-o', alpha = 0.1, lw=1, ms = 2, remove_axes=False)\n\n# set idealized lines\nax_dict['a'].axhline(y=0,xmin=0,xmax=5,c=\"black\",ls = '--', linewidth=1,zorder=0)\nax_dict['b'].axhline(y=0,xmin=0,xmax=5,c=\"black\",ls = '--', linewidth=1,zorder=0)\nax_dict['c'].axhline(y=0,xmin=0,xmax=5,c=\"black\",ls = '--', linewidth=1,zorder=0)\nax_dict['d'].axhline(y=0,xmin=0,xmax=5,c=\"black\",ls = '--', linewidth=1,zorder=0)\n\nax_dict['a'].get_shared_y_axes().join(ax_dict['a'], ax_dict['b'], ax_dict['c'], ax_dict['d'])\nax_dict['b'].get_shared_y_axes().join(ax_dict['a'], ax_dict['b'], ax_dict['c'], ax_dict['d'])\n\nprint(\"mean values of the DF0 matrix: \", np.mean(ed_all[:, -3:], axis = (0, 1)))\nprint(\"std values of the DF0 matrix: \", np.std(ed_all[:, -3:], axis = (0, 1)))\nfig_encdec\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# target velocity contribution\n\nenc_dim = encoder_linear[:, :, :, :, :, idx_dict['targ_vel_idx']] # use reference only\n\n\n# calculate the decoder-encoder pairs here\nenc_dec = np.zeros((utils.n_blocks, utils.n_keys, utils.n_conds, len(update_ix) - 2, 2, 2))\nenc_dec_control = np.zeros_like((enc_dec))\n\n## takes a long time to run!\nfor iK, key in enumerate(keys):\n    # block 1\n    b = 0\n    dec1 = decoders[b, iK][:, 1:-1]\n    enc1 = enc_dim[b, iK] # [:, np.newaxis]\n    enc_dec[b, iK] = dec1@enc1\n\n    # block 1\n    b = 1\n    dec2 = decoders[b, iK][:, 1:-1]\n    enc2 = enc_dim[b, iK] #[:, np.newaxis]\n    enc_dec[b, iK] = dec2@enc2\n\n\ned_all = np.mean(enc_dec, axis = (0, 2))\ned_all_control = np.mean(enc_dec_control, axis = (0, 2))\n\n# ld_low\n# [e  f]\n# [g  h]\nplotting.plot_time_domain(t_upd/60, ed_all[:, :, 0, 0], axis = 0, ax=ax_dict['e'], \n                          color = utils.colors['FF'], ls='-o', alpha = 0.1, lw=1, ms = 2, remove_axes=False)\nplotting.plot_time_domain(t_upd/60, ed_all[:, :, 0, 1], axis = 0, ax=ax_dict['f'], \n                          color = utils.colors['FF'], ls='-o', alpha = 0.1, lw=1, ms = 2, remove_axes=False)\nplotting.plot_time_domain(t_upd/60, ed_all[:, :, 1, 0], axis = 0, ax=ax_dict['g'],\n                          color = utils.colors['FF'], ls='-o', alpha = 0.1, lw=1, ms = 2, remove_axes=False)\nplotting.plot_time_domain(t_upd/60, ed_all[:, :, 1, 1], axis = 0, ax=ax_dict['h'], \n                          color = utils.colors['FF'], ls='-o', alpha = 0.1, lw=1, ms = 2, remove_axes=False)\n\n\n# set idealized lines\nax_dict['e'].axhline(y=1,xmin=0,xmax=5,c='k',ls = '--', linewidth=1,zorder=0)\nax_dict['f'].axhline(y=0,xmin=0,xmax=5,c='k',ls = '--', linewidth=1,zorder=0)\nax_dict['g'].axhline(y=0,xmin=0,xmax=5,c='k',ls = '--', linewidth=1,zorder=0)\nax_dict['h'].axhline(y=1,xmin=0,xmax=5,c='k',ls = '--', linewidth=1,zorder=0)\n\n# share y-axis\nax_dict['e'].get_shared_y_axes().join(ax_dict['e'], ax_dict['f'], ax_dict['g'], ax_dict['h'])\nax_dict['f'].get_shared_y_axes().join(ax_dict['e'], ax_dict['f'], ax_dict['g'], ax_dict['h'])\n\n\nprint(\"mean values of the DF1 matrix: \", np.mean(ed_all[:, -3:], axis = (0, 1)))\nprint(\"std values of the DF1 matrix: \", np.std(ed_all[:, -3:], axis = (0, 1)))\n\nfig_encdec\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# target position error contribution - DB_0\n\nenc_dim = encoder_linear[:, :, :, :, :, idx_dict['targ_pos_err_idx']] # use reference only\n\n\n# calculate the decoder-encoder pairs here\nenc_dec = np.zeros((utils.n_blocks, utils.n_keys, utils.n_conds, len(update_ix) - 2, 2, 2))\nenc_dec_control = np.zeros_like((enc_dec))\n\n## takes a long time to run!\nfor iK, key in enumerate(keys):\n    # block 1\n    b = 0\n    dec1 = decoders[b, iK][:, 1:-1]\n    enc1 = enc_dim[b, iK] # [:, np.newaxis]\n    enc_dec[b, iK] = dec1@enc1\n\n    # block 1\n    b = 1\n    dec2 = decoders[b, iK][:, 1:-1]\n    enc2 = enc_dim[b, iK] #[:, np.newaxis]\n    enc_dec[b, iK] = dec2@enc2\n\n\ned_all = np.mean(enc_dec, axis = (0, 2))\ned_all_control = np.mean(enc_dec_control, axis = (0, 2))\n\n# ld_low\n# [ i  j]\n# [ k  l]\nplotting.plot_time_domain(t_upd/60, ed_all[:, :, 0, 0], axis = 0, ax=ax_dict['i'], \n                          color = utils.colors['FB'], ls='-o', alpha = 0.1, lw=1, ms = 2, remove_axes=False)\nplotting.plot_time_domain(t_upd/60, ed_all[:, :, 0, 1], axis = 0, ax=ax_dict['j'], \n                          color = utils.colors['FB'], ls='-o', alpha = 0.1, lw=1, ms = 2, remove_axes=False)\nplotting.plot_time_domain(t_upd/60, ed_all[:, :, 1, 0], axis = 0, ax=ax_dict['k'],\n                          color = utils.colors['FB'], ls='-o', alpha = 0.1, lw=1, ms = 2, remove_axes=False)\nplotting.plot_time_domain(t_upd/60, ed_all[:, :, 1, 1], axis = 0, ax=ax_dict['l'], \n                          color = utils.colors['FB'], ls='-o', alpha = 0.1, lw=1, ms = 2, remove_axes=False)\n\n# idealized values\nax_dict['j'].axhline(y=0,xmin=0,xmax=5,c=\"black\",ls = '--', linewidth=1,zorder=10)\nax_dict['k'].axhline(y=0,xmin=0,xmax=5,c=\"black\",ls = '--', linewidth=1,zorder=10)\n\n# share y-axis\nax_dict['j'].get_shared_y_axes().join(ax_dict['i'], ax_dict['j'], ax_dict['k'], ax_dict['l'])\n\nprint(\"mean values of the DB0 matrix: \", np.mean(ed_all[:, -3:], axis = (0, 1)))\nprint(\"std values of the DB0 matrix: \", np.std(ed_all[:, -3:], axis = (0, 1)))\nprint(\"eigen values of the DB0 matrix: \", np.linalg.eigvals(np.mean(ed_all[:, -3:], axis = (0, 1))))\n\nfig_encdec"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# target velocity error contribution\n\nenc_dim = encoder_linear[:, :, :, :, :, idx_dict['targ_vel_err_idx']] # use reference only\n\n\n# calculate the decoder-encoder pairs here\nenc_dec = np.zeros((utils.n_blocks, utils.n_keys, utils.n_conds, len(update_ix) - 2, 2, 2))\nenc_dec_control = np.zeros_like((enc_dec))\n\n## takes a long time to run!\nfor iK, key in enumerate(keys):\n    # block 1\n    b = 0\n    dec1 = decoders[b, iK][:, 1:-1]\n    enc1 = enc_dim[b, iK] # [:, np.newaxis]\n    enc_dec[b, iK] = dec1@enc1\n\n    # block 1\n    b = 1\n    dec2 = decoders[b, iK][:, 1:-1]\n    enc2 = enc_dim[b, iK] #[:, np.newaxis]\n    enc_dec[b, iK] = dec2@enc2\n\n\ned_all = np.mean(enc_dec, axis = (0, 2))\n\ned_all_control = np.mean(enc_dec_control, axis = (0, 2))\n\n# ld_low\n# [ m  n]\n# [ o  p]\nplotting.plot_time_domain(t_upd/60, ed_all[:, :, 0, 0], axis = 0, ax=ax_dict['m'], \n                          color = utils.colors['FB'], ls='-o', alpha = 0.1, lw=1, ms = 2, remove_axes=False)\nplotting.plot_time_domain(t_upd/60, ed_all[:, :, 0, 1], axis = 0, ax=ax_dict['n'], \n                          color = utils.colors['FB'], ls='-o', alpha = 0.1, lw=1, ms = 2, remove_axes=False)\nplotting.plot_time_domain(t_upd/60, ed_all[:, :, 1, 0], axis = 0, ax=ax_dict['o'],\n                          color = utils.colors['FB'], ls='-o', alpha = 0.1, lw=1, ms = 2, remove_axes=False)\nplotting.plot_time_domain(t_upd/60, ed_all[:, :, 1, 1], axis = 0, ax=ax_dict['p'], \n                          color = utils.colors['FB'], ls='-o', alpha = 0.1, lw=1, ms = 2, remove_axes=False)\n\n# idealized values\nax_dict['n'].axhline(y=0,xmin=0,xmax=5,c=\"black\",ls = '--', linewidth=1,zorder=10)\nax_dict['o'].axhline(y=0,xmin=0,xmax=5,c=\"black\",ls = '--', linewidth=1,zorder=10)\n\n# share y-axis\nax_dict['n'].get_shared_y_axes().join(ax_dict['m'], ax_dict['n'], ax_dict['o'], ax_dict['p'])\n\nprint(\"mean values of the DB1 matrix: \", np.mean(ed_all[:, -3:], axis = (0, 1)))\nprint(\"std values of the DB1 matrix: \", np.std(ed_all[:, -3:], axis = (0, 1)))\nprint(\"eigen values of the DB1 matrix: \", np.linalg.eigvals(np.mean(ed_all[:, -3:], axis = (0, 1))))\n\n\nfig_encdec"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# fig q\nex_subj = 1\nex_enc_change = np.append(enc_change_across_trials[0, ex_subj], enc_change_across_trials[1, ex_subj])\nex_enc_change_all = np.append(enc_change_across_trials[0, :], enc_change_across_trials[1, :], axis = -1)\n\nplotting.plot_time_domain(x_ticks, ex_enc_change_all, axis = 0,\n                          lw = 1, ls = '-o', ms = 2,\n                          remove_axes=False, ax = ax_dict['q'], color=utils.colors['E'])\nfig_encdec"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"encoder_linear.shape"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"E_diff = np.linalg.norm(np.diff(encoder_linear, axis = 3), 'fro', axis = (-1, -2))\nE_diff.shape"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"E_diff = np.linalg.norm(np.diff(encoder_linear, axis = 3), 'fro', axis = (-1, -2))\nE_diff_subj = np.mean(E_diff, axis = (0, 2))\n\nplotting.plot_time_domain(np.linspace(0.6, 5, 15), E_diff_subj[:, 1:], axis = 0,\n                          lw = 1, ls = '-o', ms = 2,\n                          remove_axes=False, ax = ax_dict['s'], color=utils.colors['E'])\n\n# plotting.plot_time_domain(np.linspace(0.6, 5, 16), E_diff_subj[:, :], axis = 0,\n#                           lw = 1, ls = '-o', ms = 2,\n#                           remove_axes=False, ax = ax_dict['s'], color=utils.colors['E'])\n\n# ax_dict['s'].plot(E_diff_subj[:, 1:].T, lw = 1)\nfig_encdec\n# plt.plot(E_diff_subj[:, 1:].T)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"image_format = 'pdf' # e.g .png, .svg, etc.\nimage_name = 'fig2-encoder-decoder-mean.pdf'\n\nPATH = '/results/'\nfig_encdec.savefig(PATH + image_name, format=image_format, dpi=300)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"analysis_env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":2}