{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"import pickle\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.stats import wilcoxon as wilcoxon\nfrom matplotlib.ticker import AutoMinorLocator, MultipleLocator\n\n# meta analysis functions\nimport sys\nsys.path.append('/code/')\nfrom util import analysis\nfrom util import plotting\nfrom util import util_continuous as utils\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"PATH = 'data/'"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"with open(PATH + 'encoder-estimation-data/encoder-decoder-data.pickle', 'rb') as handle:\n    encoder, encoder_r2, idx_dict, pos_vel_model, pos, dec_vels, decoders = pickle.load(handle)\nkeys = ['METACPHS_S106', 'METACPHS_S107','METACPHS_S108', 'METACPHS_S109', 'METACPHS_S110', 'METACPHS_S111', 'METACPHS_S112', 'METACPHS_S113', 'METACPHS_S114', 'METACPHS_S115', 'METACPHS_S116', 'METACPHS_S117', 'METACPHS_S118', 'METACPHS_S119']\n\n\nwith open(PATH + 'trial-related-data/times-decoder-update.pickle','rb') as handle:\n    update_ix, update_times = pickle.load(handle)\n# load the order of the trials in terms of when the subject saw the trial\nwith open(PATH + 'trial-related-data/decoder_trials_in_order.pickle','rb') as handle:\n    trials_list, conds_trial_list = pickle.load(handle)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# check the encoder shape to match as expected\nassert(encoder.shape == (utils.n_blocks, utils.n_keys, utils.n_conds, len(update_ix) - 2, utils.n_ch, 9))\nencoder_linear = encoder[:, :, :, :, :, :-1]\n\n# remove the affine term from the encoder\nassert(encoder_linear.shape == (utils.n_blocks, utils.n_keys, utils.n_conds, len(update_ix) - 2, utils.n_ch, 8))\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"import matplotlib.ticker as ticker\n\nlabel_size = 6\n## SETUP THE FIGURE HERE\n## HAVE TO RE-REUN FROM HERE TO \"CLEAR\" THE PLOT\nfig_encdec = plt.figure(figsize = (6.5, 4), layout='constrained') # set the total figure size\nmosaic = \"\"\"\n    aabb.eeff\n    ccdd.gghh\n    .........\n    iijj.mmnn\n    kkll.oopp\n    \"\"\"\n\n# set up the axes\nax_dict = fig_encdec.subplot_mosaic(mosaic)\nfor ii in ax_dict:\n    plotting.remove_and_set_axes(ax_dict[ii], bottom=True, left=True)\n    ax_dict[ii].tick_params(axis='both', which='major', labelsize = label_size)\n    ax_dict[ii].tick_params(axis='both', which='minor', labelsize = label_size)\n    # set the x-ticks at multiples of 1\n    ax_dict[ii].xaxis.set_major_locator(ticker.MultipleLocator(base=5))\n    ax_dict[ii].xaxis.set_minor_locator(ticker.MultipleLocator(base=1))\nfig_encdec.patch.set_facecolor('white')\n\n\nax_dict['a'].set_title(\"$D \\cdot F_0$\")\n\n\nax_dict['a'].set_ylabel(\"(0, 0)\")\nax_dict['b'].set_ylabel(\"(0, 1)\")\nax_dict['c'].set_ylabel(\"(1, 0)\")\nax_dict['d'].set_ylabel(\"(1, 1)\")\n\nax_dict['e'].set_title(\"$D \\cdot F_1$\")\n\nax_dict['e'].set_ylabel(\"(0, 0)\")\nax_dict['f'].set_ylabel(\"(0, 1)\")\nax_dict['g'].set_ylabel(\"(1, 0)\")\nax_dict['h'].set_ylabel(\"(1, 1)\")\n\nax_dict['i'].set_title(\"$D \\cdot B_0$\")\n\nax_dict['i'].set_ylabel(\"(0, 0)\")\nax_dict['j'].set_ylabel(\"(0, 1)\")\nax_dict['k'].set_ylabel(\"(1, 0)\")\nax_dict['l'].set_ylabel(\"(1, 1)\")\n\nax_dict['m'].set_title(\"$D \\cdot B_1$\")\n\nax_dict['m'].set_ylabel(\"(0, 0)\")\nax_dict['n'].set_ylabel(\"(0, 1)\")\nax_dict['o'].set_ylabel(\"(1, 0)\")\nax_dict['p'].set_ylabel(\"(1, 1)\")\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"## set up the time axis\nt_upd = update_times[1:-1]"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"idx_dict"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# plots a, b, c, d\n# target position contribution (D * F0)\nenc_dim = encoder_linear[:, :, :, :, :, idx_dict['targ_pos_idx']] \n\n# calculate the decoder-encoder pairs here\nenc_dec = np.zeros((utils.n_blocks, utils.n_keys, utils.n_conds, len(update_ix) - 2, 2, 2))\nenc_dec_control = np.zeros_like((enc_dec))\n\n\n## takes a long time to run!\nfor iK, key in enumerate(keys):\n    # block 1\n    b = 0\n    # dec1 = Ws_block1[key][:, update_ix][:, 1:-1] # make the shape the same as the encoder - 8 x 17 x 2 x 64\n    dec1 = decoders[b, iK][:, 1:-1]\n    enc1 = enc_dim[b, iK] # [:, np.newaxis]\n    enc_dec[b, iK] = dec1@enc1\n    \n    # block 1\n    b = 1\n    # dec2 = Ws_block2[key][:, update_ix][:, 1:-1]\n    dec2 = decoders[b, iK][:, 1:-1]\n    enc2 = enc_dim[b, iK] #[:, np.newaxis]\n    enc_dec[b, iK] = dec2@enc2\n\ned_all = np.mean(enc_dec, axis = (0, 2))\n\n# take the average of the slow conditions and the fast conditions\ned_all_slow = np.mean(enc_dec[:, :, utils.slow], axis = (0, 2))\ned_all_fast = np.mean(enc_dec[:, :, utils.fast], axis = (0, 2))\n# shape is that each subject has a slow/fast decoder-encoder at each timepoint to graph\nassert(ed_all_slow.shape == (utils.n_keys, len(update_ix) - 2, 2, 2))\nassert(ed_all_fast.shape == (utils.n_keys, len(update_ix) - 2, 2, 2))\n\n# learning rate = low\n# a, b\n# c, d\nplotting.plot_time_domain(t_upd/60, ed_all_slow[:, :, 0, 0], \n                          axis = 0, ax = ax_dict['a'], color = 'blue', ls='-o', alpha = 0.4, lw=1, remove_axes = False)\nplotting.plot_time_domain(t_upd/60, ed_all_slow[:, :, 0, 1], \n                          axis = 0, ax = ax_dict['b'], color = 'blue', ls='-o', alpha = 0.4, lw=1, remove_axes = False)\nplotting.plot_time_domain(t_upd/60, ed_all_slow[:, :, 1, 0],\n                          axis = 0, ax = ax_dict['c'], color = 'blue', ls='-o', alpha = 0.4, lw=1, remove_axes = False)\nplotting.plot_time_domain(t_upd/60, ed_all_slow[:, :, 1, 1], \n                          axis = 0, ax = ax_dict['d'], color = 'blue', ls='-o', alpha = 0.4, lw=1, remove_axes = False)\n\nplotting.plot_time_domain(t_upd/60, ed_all_fast[:, :, 0, 0], \n                          axis = 0, ax = ax_dict['a'], color = 'red', ls='-o', alpha = 0.4, lw=1, remove_axes = False)\nplotting.plot_time_domain(t_upd/60, ed_all_fast[:, :, 0, 1], \n                          axis = 0, ax = ax_dict['b'], color = 'red', ls='-o', alpha = 0.4, lw=1, remove_axes = False)\nplotting.plot_time_domain(t_upd/60, ed_all_fast[:, :, 1, 0], \n                          axis = 0, ax = ax_dict['c'], color = 'red', ls='-o', alpha = 0.4, lw=1, remove_axes = False)\nplotting.plot_time_domain(t_upd/60, ed_all_fast[:, :, 1, 1], \n                          axis = 0, ax = ax_dict['d'], color = 'red', ls='-o', alpha = 0.4, lw=1, remove_axes = False)\n\n# fig_encdec.legend(['slow', '', 'fast'])\n\n\n# set idealized lines\nax_dict['a'].axhline(y=0,xmin=0,xmax=5,c=\"black\",ls = '--', linewidth=1,zorder=0)\nax_dict['b'].axhline(y=0,xmin=0,xmax=5,c=\"black\",ls = '--', linewidth=1,zorder=0)\nax_dict['c'].axhline(y=0,xmin=0,xmax=5,c=\"black\",ls = '--', linewidth=1,zorder=0)\nax_dict['d'].axhline(y=0,xmin=0,xmax=5,c=\"black\",ls = '--', linewidth=1,zorder=0)\n\nax_dict['a'].get_shared_y_axes().join(ax_dict['a'], ax_dict['b'], ax_dict['c'], ax_dict['d'])\n\n\n\n\n# fig.suptitle(\"Target Velocity Contribution\")\nfig_encdec\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# plots e,f,g,h\n# target velocity contribution (D * F1)\nenc_dim = encoder_linear[:, :, :, :, :, idx_dict['targ_vel_idx']] \n\n# calculate the decoder-encoder pairs here\nenc_dec = np.zeros((utils.n_blocks, utils.n_keys, utils.n_conds, len(update_ix) - 2, 2, 2))\nenc_dec_control = np.zeros_like((enc_dec))\n\n\n## takes a long time to run!\nfor iK, key in enumerate(keys):\n    # block 1\n    b = 0\n    # dec1 = Ws_block1[key][:, update_ix][:, 1:-1] # make the shape the same as the encoder - 8 x 17 x 2 x 64\n    dec1 = decoders[b, iK][:, 1:-1]\n    enc1 = enc_dim[b, iK] # [:, np.newaxis]\n    enc_dec[b, iK] = dec1@enc1\n    \n    # block 1\n    b = 1\n    # dec2 = Ws_block2[key][:, update_ix][:, 1:-1]\n    dec2 = decoders[b, iK][:, 1:-1]\n    enc2 = enc_dim[b, iK] #[:, np.newaxis]\n    enc_dec[b, iK] = dec2@enc2\n\ned_all = np.mean(enc_dec, axis = (0, 2))\n\n# take the average of the slow conditions and the fast conditions\ned_all_slow = np.mean(enc_dec[:, :, utils.slow], axis = (0, 2))\ned_all_fast = np.mean(enc_dec[:, :, utils.fast], axis = (0, 2))\n# shape is that each subject has a slow/fast decoder-encoder at each timepoint to graph\nassert(ed_all_slow.shape == (utils.n_keys, len(update_ix) - 2, 2, 2))\nassert(ed_all_fast.shape == (utils.n_keys, len(update_ix) - 2, 2, 2))\n\n# learning rate = low\n# e, f\n# g, h\nplotting.plot_time_domain(t_upd/60, ed_all_slow[:, :, 0, 0], \n                          axis = 0, ax = ax_dict['e'], color = 'blue', ls='-o', alpha = 0.4, lw=1, remove_axes = False)\nplotting.plot_time_domain(t_upd/60, ed_all_slow[:, :, 0, 1], \n                          axis = 0, ax = ax_dict['f'], color = 'blue', ls='-o', alpha = 0.4, lw=1, remove_axes = False)\nplotting.plot_time_domain(t_upd/60, ed_all_slow[:, :, 1, 0],\n                          axis = 0, ax = ax_dict['g'], color = 'blue', ls='-o', alpha = 0.4, lw=1, remove_axes = False)\nplotting.plot_time_domain(t_upd/60, ed_all_slow[:, :, 1, 1], \n                          axis = 0, ax = ax_dict['h'], color = 'blue', ls='-o', alpha = 0.4, lw=1, remove_axes = False)\n\nplotting.plot_time_domain(t_upd/60, ed_all_fast[:, :, 0, 0], \n                          axis = 0, ax = ax_dict['e'], color = 'red', ls='-o', alpha = 0.4, lw=1, remove_axes = False)\nplotting.plot_time_domain(t_upd/60, ed_all_fast[:, :, 0, 1], \n                          axis = 0, ax = ax_dict['f'], color = 'red', ls='-o', alpha = 0.4, lw=1, remove_axes = False)\nplotting.plot_time_domain(t_upd/60, ed_all_fast[:, :, 1, 0], \n                          axis = 0, ax = ax_dict['g'], color = 'red', ls='-o', alpha = 0.4, lw=1, remove_axes = False)\nplotting.plot_time_domain(t_upd/60, ed_all_fast[:, :, 1, 1], \n                          axis = 0, ax = ax_dict['h'], color = 'red', ls='-o', alpha = 0.4, lw=1, remove_axes = False)\n\n# fig_encdec.legend(['slow', '', 'fast'])\n\n# set idealized lines\nax_dict['e'].axhline(y=1,xmin=0,xmax=5,c='k',ls = '--', linewidth=1,zorder=0)\nax_dict['f'].axhline(y=0,xmin=0,xmax=5,c='k',ls = '--', linewidth=1,zorder=0)\nax_dict['g'].axhline(y=0,xmin=0,xmax=5,c='k',ls = '--', linewidth=1,zorder=0)\nax_dict['h'].axhline(y=1,xmin=0,xmax=5,c='k',ls = '--', linewidth=1,zorder=0)\n\n# share y-axis\nax_dict['e'].get_shared_y_axes().join(ax_dict['e'], ax_dict['f'], ax_dict['g'], ax_dict['h'])\n\n\n# fig.suptitle(\"Target Velocity Contribution\")\nfig_encdec\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# plots i,j,k,l\n# target velocity contribution (D * B0)\nenc_dim = encoder_linear[:, :, :, :, :, idx_dict['targ_pos_err_idx']] \n\n# calculate the decoder-encoder pairs here\nenc_dec = np.zeros((utils.n_blocks, utils.n_keys, utils.n_conds, len(update_ix) - 2, 2, 2))\nenc_dec_control = np.zeros_like((enc_dec))\n\n\n## takes a long time to run!\nfor iK, key in enumerate(keys):\n    # block 1\n    b = 0\n    # dec1 = Ws_block1[key][:, update_ix][:, 1:-1] # make the shape the same as the encoder - 8 x 17 x 2 x 64\n    dec1 = decoders[b, iK][:, 1:-1]\n    enc1 = enc_dim[b, iK] # [:, np.newaxis]\n    enc_dec[b, iK] = dec1@enc1\n    \n    # block 1\n    b = 1\n    # dec2 = Ws_block2[key][:, update_ix][:, 1:-1]\n    dec2 = decoders[b, iK][:, 1:-1]\n    enc2 = enc_dim[b, iK] #[:, np.newaxis]\n    enc_dec[b, iK] = dec2@enc2\n\ned_all = np.mean(enc_dec, axis = (0, 2))\n\n# take the average of the slow conditions and the fast conditions\ned_all_slow = np.mean(enc_dec[:, :, utils.slow], axis = (0, 2))\ned_all_fast = np.mean(enc_dec[:, :, utils.fast], axis = (0, 2))\n# shape is that each subject has a slow/fast decoder-encoder at each timepoint to graph\nassert(ed_all_slow.shape == (utils.n_keys, len(update_ix) - 2, 2, 2))\nassert(ed_all_fast.shape == (utils.n_keys, len(update_ix) - 2, 2, 2))\n\n# learning rate = slow\n# i, j\n# k, l\nplotting.plot_time_domain(t_upd/60, ed_all_slow[:, :, 0, 0], \n                          axis = 0, ax = ax_dict['i'], color = 'blue', ls='-o', alpha = 0.4, lw=1, remove_axes = False)\nplotting.plot_time_domain(t_upd/60, ed_all_slow[:, :, 0, 1], \n                          axis = 0, ax = ax_dict['j'], color = 'blue', ls='-o', alpha = 0.4, lw=1, remove_axes = False)\nplotting.plot_time_domain(t_upd/60, ed_all_slow[:, :, 1, 0],\n                          axis = 0, ax = ax_dict['k'], color = 'blue', ls='-o', alpha = 0.4, lw=1, remove_axes = False)\nplotting.plot_time_domain(t_upd/60, ed_all_slow[:, :, 1, 1], \n                          axis = 0, ax = ax_dict['l'], color = 'blue', ls='-o', alpha = 0.4, lw=1, remove_axes = False)\n\n# learning rate = fast\nplotting.plot_time_domain(t_upd/60, ed_all_fast[:, :, 0, 0], \n                          axis = 0, ax = ax_dict['i'], color = 'red', ls='-o', alpha = 0.4, lw=1, remove_axes = False)\nplotting.plot_time_domain(t_upd/60, ed_all_fast[:, :, 0, 1], \n                          axis = 0, ax = ax_dict['j'], color = 'red', ls='-o', alpha = 0.4, lw=1, remove_axes = False)\nplotting.plot_time_domain(t_upd/60, ed_all_fast[:, :, 1, 0], \n                          axis = 0, ax = ax_dict['k'], color = 'red', ls='-o', alpha = 0.4, lw=1, remove_axes = False)\nplotting.plot_time_domain(t_upd/60, ed_all_fast[:, :, 1, 1], \n                          axis = 0, ax = ax_dict['l'], color = 'red', ls='-o', alpha = 0.4, lw=1, remove_axes = False)\n\n# fig_encdec.legend(['slow', '', 'fast'])\n\n\n# set idealized lines\nax_dict['j'].axhline(y=0,xmin=0,xmax=5,c=\"black\",ls = '--', linewidth=1,zorder=10)\nax_dict['k'].axhline(y=0,xmin=0,xmax=5,c=\"black\",ls = '--', linewidth=1,zorder=10)\n\n# share y-axis\nax_dict['j'].get_shared_y_axes().join(ax_dict['i'], ax_dict['j'], ax_dict['k'], ax_dict['l'])\n\n\nfig_encdec\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# plots m,n,o,p\n# target velocity contribution (D * B1)\nenc_dim = encoder_linear[:, :, :, :, :, idx_dict['targ_vel_err_idx']] \n\n# calculate the decoder-encoder pairs here\nenc_dec = np.zeros((utils.n_blocks, utils.n_keys, utils.n_conds, len(update_ix) - 2, 2, 2))\nenc_dec_control = np.zeros_like((enc_dec))\n\n\n## takes a long time to run!\nfor iK, key in enumerate(keys):\n    # block 1\n    b = 0\n    # dec1 = Ws_block1[key][:, update_ix][:, 1:-1] # make the shape the same as the encoder - 8 x 17 x 2 x 64\n    dec1 = decoders[b, iK][:, 1:-1]\n    enc1 = enc_dim[b, iK] # [:, np.newaxis]\n    enc_dec[b, iK] = dec1@enc1\n    \n    # block 1\n    b = 1\n    # dec2 = Ws_block2[key][:, update_ix][:, 1:-1]\n    dec2 = decoders[b, iK][:, 1:-1]\n    enc2 = enc_dim[b, iK] #[:, np.newaxis]\n    enc_dec[b, iK] = dec2@enc2\n\ned_all = np.mean(enc_dec, axis = (0, 2))\n\n# take the average of the slow conditions and the fast conditions\ned_all_slow = np.mean(enc_dec[:, :, utils.slow], axis = (0, 2))\ned_all_fast = np.mean(enc_dec[:, :, utils.fast], axis = (0, 2))\n# shape is that each subject has a slow/fast decoder-encoder at each timepoint to graph\nassert(ed_all_slow.shape == (utils.n_keys, len(update_ix) - 2, 2, 2))\nassert(ed_all_fast.shape == (utils.n_keys, len(update_ix) - 2, 2, 2))\n\n# learning rate = slow\n# m, n\n# o, p\nplotting.plot_time_domain(t_upd/60, ed_all_slow[:, :, 0, 0], \n                          axis = 0, ax = ax_dict['m'], color = 'blue', ls='-o', alpha = 0.4, lw=1, remove_axes = False)\nplotting.plot_time_domain(t_upd/60, ed_all_slow[:, :, 0, 1], \n                          axis = 0, ax = ax_dict['n'], color = 'blue', ls='-o', alpha = 0.4, lw=1, remove_axes = False)\nplotting.plot_time_domain(t_upd/60, ed_all_slow[:, :, 1, 0],\n                          axis = 0, ax = ax_dict['o'], color = 'blue', ls='-o', alpha = 0.4, lw=1, remove_axes = False)\nplotting.plot_time_domain(t_upd/60, ed_all_slow[:, :, 1, 1], \n                          axis = 0, ax = ax_dict['p'], color = 'blue', ls='-o', alpha = 0.4, lw=1, remove_axes = False)\n\n# learning rate = fast\nplotting.plot_time_domain(t_upd/60, ed_all_fast[:, :, 0, 0], \n                          axis = 0, ax = ax_dict['m'], color = 'red', ls='-o', alpha = 0.4, lw=1, remove_axes = False)\nplotting.plot_time_domain(t_upd/60, ed_all_fast[:, :, 0, 1], \n                          axis = 0, ax = ax_dict['n'], color = 'red', ls='-o', alpha = 0.4, lw=1, remove_axes = False)\nplotting.plot_time_domain(t_upd/60, ed_all_fast[:, :, 1, 0], \n                          axis = 0, ax = ax_dict['o'], color = 'red', ls='-o', alpha = 0.4, lw=1, remove_axes = False)\nplotting.plot_time_domain(t_upd/60, ed_all_fast[:, :, 1, 1], \n                          axis = 0, ax = ax_dict['p'], color = 'red', ls='-o', alpha = 0.4, lw=1, remove_axes = False)\n\nfig_encdec.legend(['slow', '', 'fast', ''],loc=\"center left\",\n          bbox_to_anchor=(1, 0, 0.5, 1))\n\n\n# idealized values\nax_dict['n'].axhline(y=0,xmin=0,xmax=5,c=\"black\",ls = '--', linewidth=1,zorder=10)\nax_dict['o'].axhline(y=0,xmin=0,xmax=5,c=\"black\",ls = '--', linewidth=1,zorder=10)\n\n# share y-axis\nax_dict['n'].get_shared_y_axes().join(ax_dict['m'], ax_dict['n'], ax_dict['o'], ax_dict['p'])\n\n\n\nfig_encdec\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"## need to re-adjust the axes\n\nax_dict['a'].set_ylim(-.5, .5)\nax_dict['a'].get_shared_y_axes().join(ax_dict['a'], ax_dict['b'], ax_dict['c'], ax_dict['d'])\n\nax_dict['e'].set_ylim(-.2, 1)\nax_dict['e'].get_shared_y_axes().join(ax_dict['e'], ax_dict['f'], ax_dict['g'], ax_dict['h'])\n\nax_dict['j'].set_ylim(-.5, .5)\nax_dict['j'].get_shared_y_axes().join(ax_dict['i'], ax_dict['j'], ax_dict['k'], ax_dict['l'])\n\nax_dict['n'].set_ylim(-1, 0.2)\nax_dict['n'].get_shared_y_axes().join(ax_dict['m'], ax_dict['n'], ax_dict['o'], ax_dict['p'])\n\nfig_encdec"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"image_format = 'pdf' # e.g .png, .svg, etc.\nimage_name = 'fig4-dec-enc-learning-rates-mean.pdf'\nPATH = '/results/'\nfig_encdec.savefig(PATH + image_name, format=image_format, dpi=300)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"analysis_env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":2}