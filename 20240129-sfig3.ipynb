{"cells":[{"cell_type":"markdown","metadata":{},"source":"Fig 5 - comparing penalty parameters"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"import pickle\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.stats import wilcoxon as wilcoxon\n\n\n# meta analysis functions\nimport sys\nsys.path.append('/code/')\nfrom util import analysis\nfrom util import plotting\nfrom util import util_continuous as utils"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"PATH = 'data/'"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"with open(PATH + 'time-domain-error/time-domain-error-30sec-in-cm.pkl','rb') as handle:\n    td_error, td_error_first, td_error_last, t0_start, t0_end, t1_end, td_diff, td_diff_slow, td_diff_fast, td_diff_pos, td_diff_neg, td_diff_pD3, td_diff_pD4 = pickle.load(handle)\n\nwith open(PATH + 'trial-related-data/decoded-intended-vels.pickle','rb') as handle:\n    dec_vels_block1, dec_vels_block2, int_vel_block1, int_vel_block2, conds =  pickle.load(handle)\n\nwith open(PATH + 'encoder-estimation-data/encoder-decoder-data.pickle', 'rb') as handle:\n    encoder, encoder_r2, idx_dict, pos_vel_model, pos, dec_vels, decoders = pickle.load(handle)\nkeys = ['METACPHS_S106', 'METACPHS_S107','METACPHS_S108', 'METACPHS_S109', 'METACPHS_S110', 'METACPHS_S111', 'METACPHS_S112', 'METACPHS_S113', 'METACPHS_S114', 'METACPHS_S115', 'METACPHS_S116', 'METACPHS_S117', 'METACPHS_S118', 'METACPHS_S119']\n\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"assert(td_error.shape == (utils.n_blocks, utils.n_keys, utils.n_conds, utils.min_time))"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"slow_pd3 = list(set(utils.slow) & set(utils.pD_3))\nslow_pd4 = list(set(utils.slow) & set(utils.pD_4))"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"label_size = 6\n## SETUP THE FIGURE HERE\n## HAVE TO RE-REUN FROM HERE TO \"CLEAR\" THE PLOT\nfig_penalty = plt.figure(figsize = (6.3, 3), layout='constrained') # set the total figure size\n# mosaic = \"\"\"\n#     aabbc.\n#     ddefgg\n#     \"\"\"\n\nmosaic = \"\"\"\n    bbcdde\n    affghh\n    \"\"\"\n\n\n# mosaic = \"\"\"\n#     aabccd\n#     effghh\n#     \"\"\"\n\n# set up the axes\nax_dict = fig_penalty.subplot_mosaic(mosaic)\nfor ii in ax_dict:\n    plotting.remove_and_set_axes(ax_dict[ii], bottom=True, left=True)\n    ax_dict[ii].tick_params(axis='both', which='major', labelsize = label_size)\n    ax_dict[ii].tick_params(axis='both', which='minor', labelsize = label_size)\nfig_penalty.patch.set_facecolor('white')\n\n# a - time-domain error/task performance\nax_dict['a'].set_title(\"performance\")\nax_dict['a'].set_ylabel('$|t - y|$')\n\n\n# b - decoder norm\nax_dict['b'].set_title(\"decoder norm\")\nax_dict['b'].set_ylabel('$|D|_F$')\nax_dict['b'].set_xlabel('Time (min)')\n\n# c - decoder norm significance\n# ax_dict['c'].set_title(\"decoder norm significance\")\nax_dict['c'].set_ylabel('$|D|_F$')\n\n\n# d - encoder norm\nax_dict['d'].set_title(\"encoder norm\")\nax_dict['d'].set_ylabel('$|E|_F$')\nax_dict['d'].set_xlabel('Time (min)')\n\n# e - decoder norm significance\n# ax_dict['e'].set_title(\"encoder norm significance\")\nax_dict['e'].set_ylabel('$|E|_F$')\n\n\n# d - encoder norm\nax_dict['d'].set_title(\"encoder norm\")\nax_dict['d'].set_ylabel('$|E|_F$')\nax_dict['d'].set_xlabel('Time (min)')\n\n# e - decoder norm significance\nax_dict['e'].set_title(\"encoder norm significance\")\nax_dict['e'].set_ylabel('$|E|_F$')\n\n# f - cursor velocity\nax_dict['f'].set_title(\"cursor velocity\")\nax_dict['f'].set_ylabel('$|v|_2$')\n\n# f - cursor velocity\nax_dict['g'].set_title(\"cursor velocity significance\")\nax_dict['g'].set_ylabel('$|v|_2$')\n\n# f - cursor velocity\nax_dict['h'].set_title(\"cursor velocity vs encoder\")\nax_dict['h'].set_ylabel('$|v_{f} - v_{i}|$')\nax_dict['h'].set_xlabel('$|E_{f} - E_{i}|$')\n\n# plt.subplots_adjust(wspace=1, hspace=0.5)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"assert(td_error[:, :, slow_pd3, -t1_end:].shape \n       == (utils.n_blocks, utils.n_keys, len(slow_pd3), t0_end - t0_start))"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"td_diff_pD3.shape"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# calculating relative errors\ntd_diff = (td_error_last - td_error_first)/td_error_first * 100\nassert(td_diff.shape == (2, len(keys), len(conds)))\n\ntd_diff_pD3 = np.mean(td_diff[:, :, slow_pd3], axis = (0, 2))\ntd_diff_pD4 = np.mean(td_diff[:, :, slow_pd4], axis = (0, 2))"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"wilcoxon(td_diff_pD3, td_diff_pD4) "},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"## a - no difference in performance between initial and end\n\naxs = ax_dict['a']\n\n## WILCOXON\n# early = first 60 seconds after ramp\ntd_error_first_med_pd3 = np.mean(td_error[:, :, slow_pd3, t0_start: t0_end], axis = (0, 2, 3))\ntd_error_last_med_pd3 = np.mean(td_error[:, :, slow_pd3, -t1_end:], axis = (0, 2, 3))\n\n# late = last 60 seconds of trial\ntd_error_first_med_pd4 = np.mean(td_error[:, :, slow_pd4, t0_start: t0_end], axis = (0, 2, 3))\ntd_error_last_med_pd4 = np.mean(td_error[:, :, slow_pd4, -t1_end:], axis = (0, 2, 3))\n\n\n# make sure that the Wilcoxon comparisons here are N of 14\nassert(td_error_first_med_pd3.shape == (utils.n_keys, )) # make sure the data is the number of subjects\nassert(td_error_first_med_pd4.shape == (utils.n_keys, )) # make sure the data is the number of subjects\nassert(td_error_last_med_pd3.shape == (utils.n_keys, )) # make sure the data is the number of subjects\nassert(td_error_last_med_pd4.shape == (utils.n_keys, )) # make sure the data is the number of subjects\n\n\n\ndata1 = np.ndarray.flatten(td_error_first_med_pd3)\ndata2 = np.ndarray.flatten(td_error_first_med_pd4)\n\ndata3 = np.ndarray.flatten(td_error_last_med_pd3)\ndata4 = np.ndarray.flatten(td_error_last_med_pd4)\n\ndata5 = td_diff_pD3 # high\ndata6 = td_diff_pD4 # low \n# data_groups = [data1, data2, data3, data4]\n# data_labels = ['high', 'low', 'high', 'low']\n# data_pos = [0, 0.4, 0.8, 1.2]\n# bplot = axs.boxplot(data_groups, \n#                     showfliers=False,\n#                     patch_artist=True,\n#                     positions=data_pos,\n#                     widths = 0.4,\n#                     boxprops=dict(edgecolor=\"none\"),\n#                      medianprops=dict(color='k', lw=1))\n\n\n# t = 0\n# if utils.colors is not None:\n#     for patch, color in zip(bplot['boxes'], [utils.colors['pD_3'], utils.colors['pD_4'], utils.colors['pD_3'], utils.colors['pD_4']]):\n#         patch.set_facecolor(color)\n#         if t < 2:\n#             patch.set_alpha(0.4)\n#         t = t + 1\n\n# # rotate labels  \n# axs.set_xticks(data_pos,data_labels, rotation=40)\n\n# w1 = wilcoxon(data1, data2) \n# print(w1)\n# plotting.plot_significance(pvalue = w1.pvalue, data1=data1, data2 = data2, data_pos = data_pos[:2], \n#                            ax=axs, lw=0.5, fontsize = label_size, y_bar = 1, y_asterix = 2)\n\n# w2 = wilcoxon(data3, data4) \n# print(w2)\n\n# plotting.plot_significance(pvalue = w2.pvalue, data1=data3, data2 = data4, data_pos = data_pos[-2:], \n#                            ax=axs, lw=0.5, fontsize = label_size, y_bar = 1, y_asterix = 2)\n\n\ndata_groups = [data5, data6]\ndata_labels = ['high', 'low']\ndata_pos = [0, 0.4]\nbplot = axs.boxplot(data_groups, \n                    showfliers=False,\n                    patch_artist=True,\n                    positions=data_pos,\n                    widths = 0.3,\n                    boxprops=dict(edgecolor=\"none\"),\n                     medianprops=dict(color='k', lw=1))\n\n\nt = 0\nif utils.colors is not None:\n    for patch, color in zip(bplot['boxes'], [utils.colors['pD_3'], utils.colors['pD_4'], utils.colors['pD_3'], utils.colors['pD_4']]):\n        patch.set_facecolor(color)\n        if t < 2:\n            patch.set_alpha(0.4)\n        t = t + 1\n\n# rotate labels  \naxs.set_xticks(data_pos,data_labels, rotation=40)\n\nw1 = wilcoxon(data5, data6) \nprint(w1)\nplotting.plot_significance(pvalue = w1.pvalue, data1=data5, data2 = data6, data_pos = data_pos, \n                           ax=axs, lw=0.5, fontsize = label_size, y_bar = 1, y_asterix = 2)\n\n\nfig_penalty"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"utils.update_ix"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"update_len = len(utils.update_ix)\nupdate_len"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"def calc_matrix_norm(M):\n    '''\n    calculates the frobenius norm squared of a 2-D matrix M\n    '''\n    M_norm = np.linalg.norm(M,'fro') #**2\n    return M_norm"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# def test_calc_matrix_norm():\n#     # using example from: https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html\n#     a = np.arange(9) - 4\n#     b = a.reshape((3, 3))\n#     ans = np.linalg.norm(b, 'fro')\n#     assert(calc_matrix_norm(b) == ans**2)\n\n#     # using definition from: https://mathworld.wolfram.com/FrobeniusNorm.html\n#     b_inner = [[b[i][j]**2 for j in range(b.shape[0])] for i in range(b.shape[1])]\n#     assert( (np.sqrt(np.sum(b_inner))**2) == calc_matrix_norm(b) )"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# b - decoder norms\n\nax = ax_dict['b']\nD_effort = np.zeros((utils.n_blocks, utils.n_keys, utils.n_conds, update_len - 1)) # 2 x 7 x 8 x 18\n# update_ix - 1 because the last update is not evenly spaced\n\n# calculate the decoder \"effort\" which is the decoder norm squared\nfor iK, key in enumerate(utils.keys):\n    for iC, cond in enumerate(conds):\n        # BLOCK 1\n        b = 0\n        W1 = decoders[b, iK, iC] #Ws_block1[key][iC][utils.update_ix] # so W1 = 19 x 2 x 64 \n        D_effort[b, iK, iC, :] = np.array([calc_matrix_norm(W1[ii]) for ii in range(update_len - 1)])\n        \n        # BLOCK 2\n        b = 1\n        W2 = decoders[b, iK, iC] # Ws_block2[key][iC][utils.update_ix] # W2 = 19 x 2 x 64\n        D_effort[b, iK, iC, :] = np.array([calc_matrix_norm(W2[ii]) for ii in range(update_len - 1)])    \n            \n# check the shape\nassert(D_effort.shape == (utils.n_blocks, utils.n_keys, utils.n_conds, update_len - 1))\n\n# check that all decoder norms were calculated\nassert(np.all(D_effort))\n\n# take the mean per subject and then interquartile across subjects\nD_norm_pd3 = np.mean(D_effort[:, :, slow_pd3], axis = (0, 2)) # so each subject has a D_norm_pd3 plot\nD_norm_pd4 = np.mean(D_effort[:, :, slow_pd4], axis = (0, 2))\n\n# axis = 0\n# make sure the N's are correctly compared\nassert(D_norm_pd3.shape == (utils.n_keys, update_len-1))\nassert(D_norm_pd4.shape == (utils.n_keys, update_len-1))\n\n\n# NOTE: taking the first time index (1:) off b/c it's the initial decoder and is very small in comparison\n##  looks weird on the graph\nD_norm_pd3_25, D_norm_pd3_50, D_norm_pd3_75 = np.percentile(D_norm_pd3[:, 1:], \n                                                            [25, 50, 75] , axis=0)\nD_norm_pd4_25, D_norm_pd4_50, D_norm_pd4_75 = np.percentile(D_norm_pd4[:, 1:], \n                                                            [25, 50, 75] , axis=0)\n\n\nxn = np.linspace(20, 300, len(D_norm_pd3_50))/60 # minutes\nax.fill_between(xn, D_norm_pd3_25, D_norm_pd3_75, \n                alpha=0.1, color = utils.colors['pD_3'], edgecolor = None)\nax.fill_between(xn, D_norm_pd4_25, D_norm_pd4_75, \n                alpha=0.1, color = utils.colors['pD_4'], edgecolor = None)\n\nax.plot(xn, D_norm_pd3_50, '-o', alpha=1, linewidth=1, markersize=1,\n        color = utils.colors['pD_3'], label = 'high $\\lambda$')#, \\lambda_D = 1e-3$')\n\nax.plot(xn, D_norm_pd4_50, '--o', alpha=1, linewidth=1, markersize=1, \n        color = utils.colors['pD_4'], label = 'low $\\lambda$') #, \\lambda_D = 1e-4$')\n\n\nax.legend(labelcolor='linecolor', handlelength=2, frameon=False,  loc='upper right', fontsize = label_size)\n\nfig_penalty"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"D_effort.shape"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"axs = ax_dict['c']\n\n# take the median per subject \nD_norm_pd3_subj = np.mean(D_effort[:, :, slow_pd3], axis = (0, 2, -1)) # so each subject has a D_norm_pd3 plot\nD_norm_pd4_subj = np.mean(D_effort[:, :, slow_pd4], axis = (0, 2, -1))\nassert(D_norm_pd3_subj.shape == D_norm_pd4_subj.shape == (utils.n_keys, ))\n\ndata1 = np.ndarray.flatten(D_norm_pd3_subj)\ndata2 = np.ndarray.flatten(D_norm_pd4_subj)\n\n\ndata_groups = [data1, data2]\ndata_labels = ['high', 'low',]\ndata_pos = [0, 0.4]\nbplot = axs.boxplot(data_groups, \n                    showfliers=False,\n                    patch_artist=True,\n                    positions=data_pos,\n                    widths = 0.3,\n                    boxprops=dict(edgecolor=\"none\"),\n                     medianprops=dict(color='k', lw=1))\n\n\nt = 0\nif utils.colors is not None:\n    for patch, color in zip(bplot['boxes'], [utils.colors['pD_3'], utils.colors['pD_4']]):\n        patch.set_facecolor(color)\n\n\n# rotate labels  \naxs.set_xticks(data_pos,data_labels, rotation=40)\n\nw1 = wilcoxon(data1, data2) \nprint(w1)\nplotting.plot_significance(pvalue = w1.pvalue, data1=data1, data2 = data2, data_pos = data_pos[:2], \n                           ax=axs, lw=0.5, fontsize = 10, y_bar = 0.3, y_asterix = 0.5)\n\nw_h = wilcoxon(data1, data2, alternative='less') \nprint(w_h)\n\n\n#w2 = wilcoxon(data3, data4) \n#print(w2)\n\n#plotting.plot_significance(pvalue = w2.pvalue, data1=data3, data2 = data4, data_pos = data_pos[-2:], \n                           \n\nfig_penalty"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"encoder.shape"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"enc_linear = encoder[:, :, :, :, :, :-1]\nassert(enc_linear.shape == (utils.n_blocks, utils.n_keys, utils.n_conds, update_len - 2, utils.n_ch, 8))"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"E = enc_linear[0, 0, 0]\nE.shape"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"np.array([calc_matrix_norm(E[ii, :, : ]) for ii in range(update_len - 2)]).shape"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# b - decoder norms\n\nax = ax_dict['d']\nE_effort = np.zeros((utils.n_blocks, utils.n_keys, utils.n_conds, update_len - 2)) # 2 x 7 x 8 x 18\n# update_ix - 1 because the last update is not evenly spaced\n\nenc_linear = encoder[:, :, :, :, :, :-1]\n# calculate the decoder \"effort\" which is the decoder norm squared\nfor iK, key in enumerate(utils.keys):\n    for iB in range(utils.n_blocks):\n        for iC, cond in enumerate(conds):\n            \n            enc = enc_linear[iB, iK, iC]# so E1 = num updates x 64 x 8\n            E_norm = np.array([calc_matrix_norm(enc[ii, :, : ]) for ii in range(update_len - 2)])\n            assert(E_norm.shape == (update_len - 2, ))\n            \n            E_effort[iB, iK, iC, :] = E_norm  \n                \n# check the shape\nassert(E_effort.shape == (utils.n_blocks, utils.n_keys, utils.n_conds, update_len - 2))\n\n# check that all decoder norms were calculated\nassert(np.all(E_effort))\n\n# take the mean per subject and then interquartile across subjects\nE_norm_pd3 = np.mean(E_effort[:, :, slow_pd3], axis = (0, 2)) # so each subject has a D_norm_pd3 plot\nE_norm_pd4 = np.mean(E_effort[:, :, slow_pd4], axis = (0, 2))\n\n# axis = 0\n# make sure the N's are correctly compared\nassert(E_norm_pd3.shape == (utils.n_keys, update_len-2))\nassert(E_norm_pd4.shape == (utils.n_keys, update_len-2))\n\n\nE_norm_pd3_25, E_norm_pd3_50, E_norm_pd3_75 = np.percentile(E_norm_pd3, [25, 50, 75] , axis=0)\nE_norm_pd4_25, E_norm_pd4_50, E_norm_pd4_75 = np.percentile(E_norm_pd4, [25, 50, 75] , axis=0)\n\n\nxn = np.linspace(20, 300, len(E_norm_pd3_50))/60 # minutes\nax.fill_between(xn, E_norm_pd3_25, E_norm_pd3_75, \n                alpha=0.1, color = utils.colors['pD_3'], edgecolor = None)\nax.fill_between(xn, E_norm_pd4_25, E_norm_pd4_75, \n                alpha=0.1, color = utils.colors['pD_4'], edgecolor = None)\n\nax.plot(xn, E_norm_pd3_50, '-o', alpha=1, linewidth=1, markersize=1,\n        color = utils.colors['pD_3'], label = 'high $\\lambda$')#, \\lambda_D = 1e-3$')\n\nax.plot(xn, E_norm_pd4_50, '--o', alpha=1, linewidth=1, markersize=1, \n        color = utils.colors['pD_4'], label = 'low $\\lambda$') #, \\lambda_D = 1e-4$')\n\n\nax.legend(labelcolor='linecolor', handlelength=2, frameon=False,  loc='upper right', fontsize = label_size)\n\nax.set_ylim(2, 8)\nfig_penalty"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"E_effort.shape"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"axs = ax_dict['e']\n\n# take the median per subject for each condition\nE_norm_pd3_subj = np.mean(E_effort[:, :, slow_pd3, :], axis = (0, 2, -1)) # so each subject has a D_norm_pd3 plot\nE_norm_pd4_subj = np.mean(E_effort[:, :, slow_pd4, :], axis = (0, 2, -1))\nassert(E_norm_pd3_subj.shape == E_norm_pd4_subj.shape == (utils.n_keys, ))\n\ndata1 = np.ndarray.flatten(E_norm_pd3_subj) # high penalty --> lower decoder --> higher encoder\ndata2 = np.ndarray.flatten(E_norm_pd4_subj) # low\nprint(data1 - data2)\n\ndata_groups = [data1, data2]\ndata_labels = ['high', 'low',]\ndata_pos = [0, 0.4]\nbplot = axs.boxplot(data_groups, \n                    showfliers=False,\n                    patch_artist=True,\n                    positions=data_pos,\n                    widths = 0.3,\n                    boxprops=dict(edgecolor=\"none\"),\n                    medianprops=dict(color='k', lw=1))\n\n\nt = 0\nif utils.colors is not None:\n    for patch, color in zip(bplot['boxes'], [utils.colors['pD_3'], utils.colors['pD_4']]):\n        patch.set_facecolor(color)\n\n\n# rotate labels  \naxs.set_xticks(data_pos,data_labels, rotation=40)\n\nw1 = wilcoxon(data1, data2) \nprint(w1)\nplotting.plot_significance(pvalue = w1.pvalue, data1=data1, data2 = data2, data_pos = data_pos[:2], \n                           ax=axs, lw=0.5, fontsize = 10, y_bar = 0.3, y_asterix = 0.5)\n\nw_h = wilcoxon(data1, data2, alternative='greater') \nprint(w_h)\n\n\n\n#w2 = wilcoxon(data3, data4) \n#print(w2)\n\n#plotting.plot_significance(pvalue = w2.pvalue, data1=data3, data2 = data4, data_pos = data_pos[-2:], \n                           \n\nfig_penalty"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"E_norm_pd3_subj"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"E_norm_pd4_subj"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"dec_vels.shape"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"np.all(dec_vels_block1['METACPHS_S106'][0, :, :] == dec_vels[0, 0, 0])"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# check data\nfor iK, key in enumerate(keys):\n    for iC, cond in enumerate(conds):\n        # block 1\n        assert(np.all(dec_vels[0, iK, iC] == dec_vels_block1[key][iC, :, :]))\n\n        # block 2\n        assert(np.all(dec_vels[1, iK, iC] == dec_vels_block2[key][iC, :, :]))"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"np.median(np.linalg.norm(dec_vels[:, :, slow_pd3], ord = 2, axis = -1), axis = (0, 2, 3)).shape"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"last_min = int(utils.min_time/5)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# f\naxs = ax_dict['g']\ndvels_pd3 = np.mean(np.linalg.norm(dec_vels[:, :, slow_pd3, :], ord = 2, axis = -1), axis = (0, 2, 3))\nassert(dvels_pd3.shape == (utils.n_keys, ))\n\n\ndvels_pd4 = np.mean(np.linalg.norm(dec_vels[:, :, slow_pd4, :], ord = 2,axis = -1), axis = (0, 2, 3))\nassert(dvels_pd4.shape == (utils.n_keys, ))\n\ndata1 = np.ndarray.flatten(dvels_pd3)\ndata2 = np.ndarray.flatten(dvels_pd4)\n\n\ndata_groups = [data1, data2]\ndata_labels = ['high', 'low',]\ndata_pos = [0, 0.4]\nbplot = axs.boxplot(data_groups, \n                    showfliers=False,\n                    patch_artist=True,\n                    positions=data_pos,\n                    widths = 0.3,\n                    boxprops=dict(edgecolor=\"none\"),\n                    medianprops=dict(color='k', lw=1))\n\n\nt = 0\nif utils.colors is not None:\n    for patch, color in zip(bplot['boxes'], [utils.colors['pD_3'], utils.colors['pD_4']]):\n        patch.set_facecolor(color)\n\n\n# rotate labels  \naxs.set_xticks(data_pos,data_labels, rotation=40)\n\nw1 = wilcoxon(data1, data2) \nprint(w1)\n\nw_h = wilcoxon(data1, data2, alternative='less') \nprint(w_h)\n\n\nplotting.plot_significance(pvalue = w1.pvalue, data1=data1, data2 = data2, data_pos = data_pos[:2], \n                           ax=axs, lw=0.5, fontsize = 10, y_bar = 0.3, y_asterix = 0.5)\n\n                           \n\nfig_penalty"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"dec_vels.shape"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"label_size = 4\n## SETUP THE FIGURE HERE\n## HAVE TO RE-REUN FROM HERE TO \"CLEAR\" THE PLOT\nfig_vel2 = plt.figure(figsize = (1, 1), layout='constrained') # set the total figure size\nmosaic = \"\"\"\n    a\n    \"\"\"\n\n# set up the axes\nax_dict2 = fig_vel2.subplot_mosaic(mosaic)\nfor ii in ax_dict2:\n    plotting.remove_and_set_axes(ax_dict2[ii], bottom=True, left=True)\n    ax_dict2[ii].tick_params(axis='both', which='major', labelsize = label_size)\n    ax_dict2[ii].tick_params(axis='both', which='minor', labelsize = label_size)\nfig_vel2.patch.set_facecolor('white')"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"dvels_pd3 = np.mean(np.linalg.norm(dec_vels[:, :, slow_pd3], ord = 2, axis = -1), axis = (0, 2))\ndvels_pd4 = np.mean(np.linalg.norm(dec_vels[:, :, slow_pd4], ord = 2,axis = -1), axis = (0, 2))\n\n\ndvels_pd3_25, dvels_pd3_50, dvels_pd3_75 = np.percentile(dvels_pd3, [25, 50, 75] , axis=0)\ndvels_pd4_25, dvels_pd4_50, dvels_pd4_75 = np.percentile(dvels_pd4, [25, 50, 75] , axis=0)\n\n# fig, ax = plt.subplots(1, 1, figsize=(2, 2))\n\n# ax = ax_dict2['a']\nax = ax_dict['f']\nkernal_size = int((utils.min_time)/300 * 10) # in seconds\nplotting.plot_smooth_time_domain(np.linspace(0, 5, utils.min_time), dvels_pd3, data_len=utils.n_keys, \n                                 axis=0, kernal_size=kernal_size,ax=ax, lw =1, color = utils.colors['pD_3'], remove_axes=False)\nplotting.plot_smooth_time_domain(np.linspace(0, 5, utils.min_time), dvels_pd4, data_len=utils.n_keys, \n                                 axis=0, kernal_size=kernal_size,ax=ax, lw =1, color = utils.colors['pD_4'], remove_axes=False)\n\n# fig_vel2\nfig_penalty"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"image_format = 'pdf' # e.g .png, .svg, etc.\nimage_name = 'sfig-penalty-slow-only.pdf'\nPATH = '/results/'\nfig_penalty.savefig(PATH + image_name, format=image_format, dpi=300)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"analysis_env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":2}