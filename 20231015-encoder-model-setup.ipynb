{"cells":[{"cell_type":"markdown","metadata":{},"source":"# Encoder Estimation\n\n## Author: Maneeshika Madduri\n\n### Goal\nThis code takes EMG data and estimtes an encoding model such that:\n\nEMG = Encoder $\\times$ task data\n\nFrom the EMG data, we estimate an encoder\n\n### Encoder Model\n\n$$ EMG = W*u $$\n\n$$ u = \n\\begin{bmatrix}\nr_x \\\\ r_y \\\\ \\dot{r_x} \\\\ \\dot{r_y}  \\\\ r_x - p_x \\\\ r_y - p_y \\\\ \\dot{r_x} - \\dot{p_x}   \\\\ \\dot{r_y} - \\dot{p_y} \\\\ 1\n\\end{bmatrix}\n$$\n\nwhere \n$$\nFF = \\begin{bmatrix}\nr_x \\\\ r_y \\\\ \\dot{r_x} \\\\ \\dot{r_y} \n\\end{bmatrix}\n,\nFB = \\begin{bmatrix}\nr_x - p_x \\\\ r_y - p_y \\\\ \\dot{r_x} - v_{dec,x}  \\\\ \\dot{r_y} - v_{dec,y} \n\\end{bmatrix}\n,\nb = \\begin{bmatrix}\n 1\n\\end{bmatrix}\n$$\n\nSo $W \\in R^{64 \\times 9}$"},{"cell_type":"markdown","metadata":{},"source":"### STEP 1: Load Python Packages"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"import pickle\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.stats import wilcoxon as wilcoxon\n\n# meta analysis functions\nimport sys\nsys.path.append('/code/')\nfrom util import analysis\nfrom util import plotting\nfrom util import util_continuous as utils\n\n# seaborn.set()"},{"cell_type":"markdown","metadata":{},"source":"### STEP 2: Load Data"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# path = '/Volumes/My Passport/cphs'\npath = '/data/'\n\nwith open(path + '/continuous_full_data_block1_sorted.pickle', 'rb') as handle:\n    refs_block1, poss_block1, dec_vels_block1, int_vel_block1, emgs_block1, Ws_block1, Hs_block1, alphas_block1, pDs_block1, times_block1, conditions_block1 = pickle.load(handle)\nkeys = ['METACPHS_S106', 'METACPHS_S107','METACPHS_S108', 'METACPHS_S109', 'METACPHS_S110', 'METACPHS_S111', 'METACPHS_S112', 'METACPHS_S113', 'METACPHS_S114', 'METACPHS_S115', 'METACPHS_S116', 'METACPHS_S117', 'METACPHS_S118', 'METACPHS_S119']\n\nwith open(path + '/continuous_full_data_block2_sorted.pickle', 'rb') as handle:\n    refs_block2, poss_block2, dec_vels_block2, int_vel_block2, emgs_block2, Ws_block2, Hs_block2, alphas_block2, pDs_block2, times_block2, conditions_block2 = pickle.load(handle)\nkeys = ['METACPHS_S106', 'METACPHS_S107','METACPHS_S108', 'METACPHS_S109', 'METACPHS_S110', 'METACPHS_S111', 'METACPHS_S112', 'METACPHS_S113', 'METACPHS_S114', 'METACPHS_S115', 'METACPHS_S116', 'METACPHS_S117', 'METACPHS_S118', 'METACPHS_S119']\n\n# reference (aka target) and reference velocity (aka target velocity) data \nwith open(path + '/ref_vel_data.pickle', 'rb') as handle:\n    times, refs, ref_vels = pickle.load(handle)"},{"cell_type":"markdown","metadata":{},"source":"### STEP 3: Set up utils"},{"cell_type":"markdown","metadata":{},"source":"Experimental Utils"},{"cell_type":"markdown","metadata":{},"source":"saved as:\n\n0 = D_1 (fast, pd3 = high $\\lambda$, +)\n\n1 = D_2 (fast, pd4 = low $\\lambda$, +)\n\n2 = D_5 (fast, pd3 = high $\\lambda$, -)\n\n3 = D_6 (fast, pd4 = low $\\lambda$, -)\n\n4 = D_3 (slow, pd3 = high $\\lambda$, +)\n\n5 = D_4 (slow, pd4 = low $\\lambda$, +)\n\n6 = D_7 (slow, pd3 = high $\\lambda$, -)\n\n7 = D_8 (slow, pd4 = low $\\lambda$, -)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"key = keys[0]\nalphas = alphas_block1[key]\nprint(alphas)\n\nconds = conditions_block1[key]\nprint(conds)\n\npDs = pDs_block1[key]\nprint(pDs)\n\n# initialization conditions\npos_init = [0, 1, 4, 5]\nneg_init = [2, 3, 6, 7]\n\n# penalty parameter conditions\npD_3 = [0, 2, 4, 6] # pD = 1e-3\npD_4 = [1, 3, 5, 7] # pD = 1e-4\n\n# learning rate conditions\nslow = [4, 5, 6, 7] \nfast = [0, 1, 2, 3]\n\n# dimensions\nn_keys = len(keys) # number of subjects = length of keys\nn_blocks = 2 # number of blocks = 2\n# number of decoder conditions, time samples, number of emg channels \nn_conds, n_time, n_feat = emgs_block1[keys[0]].shape \nn_dim = 2 # number of dimensions of the task (2D trajectory tracking)\n\n# set the time of the ramp at the start of each trial\ntime_x = times_block1[keys[0]][0]\nramp = np.where(time_x > 5)[0][0]\nprint(ramp)"},{"cell_type":"markdown","metadata":{},"source":"Code to check that separation has been run correctly\n\nNote: Checked Oct 12 2023"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# check that the separation is correct \n\n\nfor key in keys:\n   assert(np.all(alphas_block1[key][slow] == 0.75))\n   assert(np.all(alphas_block2[key][slow] == 0.75))\n   assert(np.all(alphas_block1[key][fast] == 0.25))\n   assert(np.all(alphas_block2[key][fast] == 0.25))\n\nfor key in keys:\n    # check all elements of positive init decoder are greater than 0\n    assert((Ws_block1[key][pos_init][:, 0] > 0).all() == True)\n    assert((Ws_block2[key][pos_init][:, 0] > 0).all() == True)\n\n    # check all elements of negative init decoder are greater than 0\n    assert((Ws_block1[key][neg_init][:, 0] < 0).all() == True)\n    assert((Ws_block2[key][neg_init][:, 0] < 0).all() == True)\n\nfor key in keys:\n    # check all penalty paramters are sorted correctly\n    assert((pDs_block1[key][pD_3] == 1e-3).all())\n    assert((pDs_block2[key][pD_3] == 1e-3).all())\n\n    # check all penalty paramters are sorted correctly\n    assert((pDs_block1[key][pD_4] == 1e-4).all())\n    assert((pDs_block2[key][pD_4] == 1e-4).all())\n\n    \n\n    \n"},{"cell_type":"markdown","metadata":{},"source":"Plotting Utils"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"from matplotlib import rcParams\n\n\nBLUE = '#1f77b4',\nORANGE = '#ff7f0e',\nGREEN = '#2ca02c',\nRED = '#d62728',\nPURPLE = '#9467bd',\nGOLD = '#FFD700'\n\ncolors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#FFD700', '#BDBDBD', '#676767']\n\n## set up plots\nrcParams['font.weight'] = 'ultralight'\nrcParams['font.family'] = 'sans serif'\nrcParams['mathtext.fontset'] = 'cm'\nplt.rcParams['font.size'] = 15\n\nrcParams['text.color'] = 'black'\nrcParams['axes.labelcolor'] = 'black'\nrcParams['xtick.color'] = 'black'\nrcParams['ytick.color'] = 'black'\n\nrcParams[\"legend.frameon\"] = False"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# trying to figure out how often decoder updates -- every 1202 samples\n\nW = Ws_block1[keys[0]][0]\nW[1:,:,:].shape # 7199 time points x (decoder dimensions is 2 x 6)\ndold = W[0]\nupdate_ix = []\nfor ix,d in enumerate(W[1:]):\n  if (np.array_equal(dold,d)==False):\n    update_ix.append(ix)\n    dold = d\n\nupdate_ix.append(len(W) - 1) \nupdate_ix = np.asarray(update_ix)\nupdate_ix = np.hstack([[0],update_ix])\nprint(\"update index in time indices\")\nprint(update_ix)\n\n# only go up to 20432\n\nupdate_times = times_block1[keys[0]][0][update_ix]\nprint(\"\")\nprint(\"update times in seconds\")\nprint(update_times)\n\nupdate_mins = update_times/60\nprint(\"\")\nprint(\"update times in minutes\")\nprint(update_mins)\n\ntscale = update_ix[-1]/update_times[-1]\nprint(\"\")\nprint(\"time scale conversion (index --> seconds): \", tscale)\n\nn_upd = len(update_ix) - 2 # last update is only 337 so we want 17 updates\n\n# save data_times\ndata_times = [update_ix, update_times]\n\n# PATH = '/Users/mmadduri/OneDrive - UW/PhD_Research/Data/pickle-data-from-python/'\n# with open(PATH + 'trial-related-data/times-decoder-update.pickle','wb') as handle:\n#    pickle.dump(data_times,handle,protocol=pickle.HIGHEST_PROTOCOL)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"print(n_upd)"},{"cell_type":"markdown","metadata":{},"source":"### STEP 4: Set up EMG data"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"emgs = np.zeros((n_blocks, n_keys, n_conds, n_time, n_feat))\n\nfor iK, key in enumerate(keys):\n    emgs[0, iK] = emgs_block1[key]\n    emgs[1, iK] = emgs_block2[key]"},{"cell_type":"markdown","metadata":{},"source":"### STEP 5: Set up the user input matrix (X)"},{"cell_type":"markdown","metadata":{},"source":"User Input Matrix: FF + FB model\n\n$$ EMG = W*u $$\n\n$$ u = \n\\begin{bmatrix}\nr_x \\\\ r_y \\\\ \\dot{r_x} \\\\ \\dot{r_y}  \\\\ r_x - p_x \\\\ r_y - p_y \\\\ \\dot{r_x} - \\dot{p_x}   \\\\ \\dot{r_y} - \\dot{p_y} \\\\ 1\n\\end{bmatrix}\n$$\n\nwhere \n$$\nFF = \\begin{bmatrix}\nr_x \\\\ r_y \\\\ \\dot{r_x} \\\\ \\dot{r_y} \n\\end{bmatrix}\n,\nFB = \\begin{bmatrix}\nr_x - p_x \\\\ r_y - p_y \\\\ \\dot{r_x} - \\dot{p_x}   \\\\ \\dot{r_y} - \\dot{p_y}\\end{bmatrix}\n,\nb = \\begin{bmatrix}\n 1\n\\end{bmatrix}\n$$\n\nSo $W \\in R^{64 \\times 9}$"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"poss_block1[keys[0]].shape"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"x_dim = 8 # dimensions of the user input matrix \n\n# indices of the user input matrix by \ntarg_pos_idx = [0, 1] # F0\ntarg_vel_idx = [2, 3] # F1\ntarg_pos_err_idx = [4, 5] # B0\ntarg_vel_err_idx = [6, 7] # B1\nFF_idx = [0, 1, 2, 3]\nFB_idx = [4, 5, 6, 7]\n\n# this is the user input matrix\n# will be set up as: n_time x x_dim\n# this becomes: [targ_pos targ_vel targ_pos_err targ_vel_err]\n# set to ones so that the last row is ones (for offset)\npos_vel_model = np.ones((n_blocks, n_keys, n_conds, n_time, x_dim + 1))\n\n# set up saving cursor position\ncurs_pos = np.zeros((n_blocks, n_keys, n_conds, n_time, n_dim))\n\n# set up saving target position\n# already saved as ref_vels from previous code\n\n# make sure that ref_vels is saved in the format we expect\nassert(ref_vels.shape == (n_blocks, n_keys, n_conds, n_time, n_dim))\n# make sure that format matches the other shapes\nassert(dec_vels_block1[keys[0]].shape == ref_vels[0, 0].shape)\n\n# set up saving decoded cursos velocity to be used to calculate velocity error\ncurs_vels = np.zeros((n_blocks, n_keys, n_conds, n_time, n_dim))\n\n# set up saving target position error\ntarg_pos_err = np.zeros((n_blocks, n_keys, n_conds, n_time, n_dim))\n\n# set up saving target velcoity error\ntarg_vels_err = np.zeros((n_blocks, n_keys, n_conds, n_time, n_dim))\n\n## set up the inputs individually and then set up the matrix\n# this needs to be done because the data is saved either in a dict and indexed by keys or in a matrix and indexed by iK\nfor iK, key in enumerate(keys):\n\n    # save cursor position to calculate the error \n    curs_pos[0, iK] = poss_block1[key]\n    curs_pos[1, iK] = poss_block2[key]\n\n    # save the cursor velcity\n    curs_vels[0, iK] = dec_vels_block1[key]\n    curs_vels[1, iK] = dec_vels_block2[key]\n\n    # targ pos error - this is currently the difference between the x and y position without absolute value\n    targ_pos_err[0, iK] = (refs_block1[key] - poss_block1[key]) #/np.max((refs_block1[key] - poss_block1[key]), axis = 1)[:, np.newaxis] \n    targ_pos_err[1, iK] = (refs_block2[key] - poss_block2[key]) #/np.max((refs_block2[key] - poss_block2[key]), axis = 1)[:, np.newaxis]\n    \n    # targ velocity error - difference between target velocity and cursor velocity\n    # same difference between x and y position without absolute value\n    targ_vels_err[0, iK] = (ref_vels[0, iK] - dec_vels_block1[key]) #/np.max(int_vel_block1[key] - dec_vels_block1[key], axis = 1)[:, np.newaxis]\n    targ_vels_err[1, iK]= (ref_vels[1, iK] - dec_vels_block2[key]) #/np.max(int_vel_block2[key] - dec_vels_block2[key], axis = 1)[:, np.newaxis]\n\n### set up the pos_vel_model\n\n# first 2 rows are target position\npos_vel_model[:, :, :, :, targ_pos_idx] = refs\n\n# second 2 rows are target velocity\npos_vel_model[:, :, :, :, targ_vel_idx] = ref_vels\n\n# next 2 rows are target - cursor position error\npos_vel_model[:, :, :, :, targ_pos_err_idx] = targ_pos_err\n\n# last 2 rows are target - cursor velocity error\npos_vel_model[:, :, :, :, targ_vel_err_idx] = targ_vels_err\n\n# make sure the last row is all 1's for offset\nassert(pos_vel_model[:, :, :, :, -1].all() == 1)"},{"cell_type":"markdown","metadata":{},"source":"### STEP 6: Calculate the User Encoders Using Linear Regression"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"update_ix"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# get a lot of divide by 0 because so few points in r^2\n# encoder estimation with intended velocity\n# this takes about 20 seconds to run\n\nencoder_matrix = np.zeros((n_blocks, n_keys, n_conds, n_upd, n_feat, x_dim+1)) # 2 x 14 x 8 x 64 x 5\nr2_all_upd = np.zeros((n_blocks, n_keys, n_conds, n_upd))\n\n# with the psuedoinverse\nencoder_psi = np.zeros((n_blocks, n_keys, n_conds, n_upd, n_feat, x_dim+1)) # 2 x 14 x 8 x 64 x 5\n\n\nx_data = pos_vel_model # target, target velocity \ny_data = emgs\n\nfor block in range(n_blocks):\n    for key in range(n_keys):\n        for cond in range(n_conds):\n            for upd in range(n_upd):\n                # if we print(upd), we want the last upd to be 16\n                if upd > 16:\n                    print(\"Check Indices of Encoder\")\n                # breaks down the code by decoder updates - so each encoder is estimated each time the decoder is updated\n                # ends up being 17 updates since the last update is cut short in the experiment\n                x_sample = x_data[block, key, cond, update_ix[upd]:update_ix[upd+1], 0:x_dim] # time x 8\n                # check the shapes -- time x dim\n                assert(x_sample.shape[0] >= update_ix[1]) \n                assert(x_sample.shape[-1] == x_dim) \n                y_sample = y_data[block, key, cond, update_ix[upd]:update_ix[upd+1]] # time x 64\n                assert(y_sample.shape[0] >= update_ix[1]) \n                assert(y_sample.shape[-1] == n_feat) \n                weights, intercept, r2_avg = analysis.estimate_encoder_linear(x_sample, y_sample)\n                \n                assert(weights.shape == (n_feat, x_dim))\n                # since the linear regression finds a y-intercept\n                weights_affine = np.hstack((weights, intercept[:, np.newaxis]))\n                assert(weights_affine.shape == (n_feat, x_dim + 1))\n\n                encoder_matrix[block, key, cond, upd] = weights_affine\n                r2_all_upd[block, key, cond, upd] = r2_avg\n\n                # try with the psuedoinverse to verify that the method works\n                # need to re-define x_sample here since we want the last rows of 1 in x_data for the affine term\n                x_sample = x_data[block, key, cond, update_ix[upd]:update_ix[upd+1]]\n                x_psi = np.linalg.pinv(x_sample.T)\n                A_mtx = y_sample.T@x_psi\n                assert(np.allclose(A_mtx, weights_affine))\n                encoder_psi[block, key, cond, upd] = A_mtx"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# check that the linear regression and the psuedoinverse give the same answer \n# note: linear regression is much faster, might be better optimized\nnp.allclose(encoder_psi, encoder_matrix)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# ## save the encoder model \n## commented out for codeocean/github\n\n# idx_dict = {'FF_idx': FF_idx, \n#             'FB_idx': FB_idx,\n#             'targ_pos_idx': targ_pos_idx, \n#             'targ_vel_idx': targ_vel_idx, \n#             'targ_pos_err_idx': targ_pos_err_idx,\n#             'targ_vel_err_idx': targ_vel_err_idx}\n\n\n# data = [encoder_matrix, r2_all_upd, idx_dict, pos_vel_model, curs_pos, curs_vels, Ws_block1, Ws_block2]\n\n# PATH = '/Users/mmadduri/OneDrive - UW/PhD_Research/Data/pickle-data-from-python/encoder-estimation-data/'\n# with open(PATH + 'encoder-estimation-model.pickle','wb') as handle:\n#     pickle.dump(data,handle,protocol=pickle.HIGHEST_PROTOCOL)"},{"cell_type":"markdown","metadata":{},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"source_hidden":false}},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"\n"},{"cell_type":"markdown","metadata":{},"source":""}],"metadata":{"kernelspec":{"display_name":"analysis_env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":2}