{"cells":[{"cell_type":"markdown","metadata":{},"source":"Fig 5 - comparing penalty parameters\n\nnote to maneeshika: boxplots are across entire trial as of may 2024 draft "},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"import pickle\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.stats import wilcoxon as wilcoxon\nfrom scipy.stats import ttest_rel\nimport scipy\n\n\n# meta analysis functions\nimport sys\nsys.path.append('/code/')\nfrom util import analysis\nfrom util import plotting\nfrom util import util_continuous as utils"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"PATH = '/data/'"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# using the task error that calculates time domain in cm\nwith open(PATH + 'time-domain-error/time-domain-error-30sec-in-cm.pkl','rb') as handle:\n    td_error, td_error_first, td_error_last, t0_start, t0_end, t1_end, td_diff, td_diff_slow, td_diff_fast, td_diff_pos, td_diff_neg, td_diff_pD3, td_diff_pD4 = pickle.load(handle)\n\nwith open(PATH + 'trial-related-data/decoded-intended-vels.pickle','rb') as handle:\n    dec_vels_block1, dec_vels_block2, int_vel_block1, int_vel_block2, conds =  pickle.load(handle)\n\nwith open(PATH + 'encoder-estimation-data/encoder-decoder-data.pickle', 'rb') as handle:\n    encoder, encoder_r2, idx_dict, pos_vel_model, pos, dec_vels, decoders = pickle.load(handle)\nkeys = ['METACPHS_S106', 'METACPHS_S107','METACPHS_S108', 'METACPHS_S109', 'METACPHS_S110', 'METACPHS_S111', 'METACPHS_S112', 'METACPHS_S113', 'METACPHS_S114', 'METACPHS_S115', 'METACPHS_S116', 'METACPHS_S117', 'METACPHS_S118', 'METACPHS_S119']\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"assert(td_error.shape == (utils.n_blocks, utils.n_keys, utils.n_conds, utils.min_time))"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Import seaborn\nimport seaborn as sns\n\nsns.set_theme(style=\"ticks\", rc=utils.sns_custom_params, font_scale=0.6)\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"import matplotlib.ticker as ticker\n\nlabel_size = 6\n## SETUP THE FIGURE HERE\n## HAVE TO RE-REUN FROM HERE TO \"CLEAR\" THE PLOT\nfig_penalty = plt.figure(figsize = (8, 5), layout='constrained') # set the total figure size\n# mosaic = \"\"\"\n#     aabbc.\n#     ddefgg\n#     \"\"\"\n\nmosaic = \"\"\"\n    bbcdde\n    affghh\n    \"\"\"\n\n\n# mosaic = \"\"\"\n#     aabccd\n#     effghh\n#     \"\"\"\n\n# set up the axes\nax_dict = fig_penalty.subplot_mosaic(mosaic)\nfor ii in ax_dict:\n    plotting.remove_and_set_axes(ax_dict[ii], bottom=True, left=True)\n    ax_dict[ii].tick_params(axis='both', which='major', labelsize = label_size)\n    ax_dict[ii].tick_params(axis='both', which='minor', labelsize = label_size)\n    ax_dict[ii].xaxis.set_major_locator(ticker.MultipleLocator(base=5))\n    ax_dict[ii].xaxis.set_minor_locator(ticker.MultipleLocator(base=1))\nfig_penalty.patch.set_facecolor('white')\n\n\n# a - time-domain error/task performance\n# ax_dict['a'].set_title(\"performance\")\nax_dict['a'].set_ylabel('% Change in Error')\n\n\n# b - decoder norm\nax_dict['b'].set_title(\"|D|\")\nax_dict['b'].set_ylabel('$|D|_F$')\nax_dict['b'].set_xlabel('Time (min)')\n\n# c - decoder norm significance\n# ax_dict['c'].set_title(\"decoder norm significance\")\nax_dict['c'].set_ylabel('$|D|_F$')\n\n\n# d - encoder norm\n# ax_dict['d'].set_title(\"|E|\")\nax_dict['d'].set_ylabel('$|E|_F$')\nax_dict['d'].set_xlabel('Time (min)')\n\n# e - decoder norm significance\n# ax_dict['e'].set_title(\"|E| significance\")\nax_dict['e'].set_ylabel('$|E|_F$')\n\n# f - cursor velocity\n# ax_dict['f'].set_title(\"cursor velocity\")\nax_dict['f'].set_ylabel('cursor speed (cm/s)')\n\n# f - cursor velocity\n# ax_dict['g'].set_title(\"|v| significance\")\nax_dict['g'].set_ylabel('$|v|_2$')\n\n# f - cursor velocity\n# ax_dict['h'].set_title(\"|E| vs |v|\")\nax_dict['h'].set_ylabel('$|v|$')\nax_dict['h'].set_xlabel('$|E|$')\n\nplt.subplots_adjust(wspace=.7, hspace=0.5)\n# fig_penalty.suptitle(\"$\\lambda high = D low = v low = E high$ \\n $\\lambda low = D high = v high = E low $\")\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"assert(td_error[:, :, utils.pD_3, -t1_end:].shape \n       == (utils.n_blocks, utils.n_keys, len(utils.pD_3), t0_end - t0_start))"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"td_diff_pD3.shape"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"## a - no difference in performance between initial and end\n\naxs = ax_dict['a']\n\n## WILCOXON\n# early = first 60 seconds after ramp\ntd_error_first_med_pd3 = np.mean(td_error[:, :, utils.pD_3, t0_start: t0_end], axis = (0, 2, 3))\ntd_error_last_med_pd3 = np.mean(td_error[:, :, utils.pD_3, -t1_end:], axis = (0, 2, 3))\n\n# late = last 60 seconds of trial\ntd_error_first_med_pd4 = np.mean(td_error[:, :, utils.pD_4, t0_start: t0_end], axis = (0, 2, 3))\ntd_error_last_med_pd4 = np.mean(td_error[:, :, utils.pD_4, -t1_end:], axis = (0, 2, 3))\n\n\n# make sure that the Wilcoxon comparisons here are N of 14\nassert(td_error_first_med_pd3.shape == (utils.n_keys, )) # make sure the data is the number of subjects\nassert(td_error_first_med_pd4.shape == (utils.n_keys, )) # make sure the data is the number of subjects\nassert(td_error_last_med_pd3.shape == (utils.n_keys, )) # make sure the data is the number of subjects\nassert(td_error_last_med_pd4.shape == (utils.n_keys, )) # make sure the data is the number of subjects\n\n\n\ndata1 = np.ndarray.flatten(td_error_first_med_pd3)\ndata2 = np.ndarray.flatten(td_error_first_med_pd4)\n\ndata3 = np.ndarray.flatten(td_error_last_med_pd3)\ndata4 = np.ndarray.flatten(td_error_last_med_pd4)\n\ndata5 = np.ndarray.flatten(td_diff_pD3)\ndata6 = np.ndarray.flatten(td_diff_pD4)\n\ndata_groups = [data5, data6]\ndata_labels = ['high', 'low']\ndata_pos = [0, 0.4]\nbplot = axs.boxplot(data_groups, \n                    showfliers=False,\n                    patch_artist=True,\n                    positions=data_pos,\n                    widths = 0.3,\n                    boxprops=dict(edgecolor=\"none\"),\n                     medianprops=dict(color='k', lw=1))\n\n\nt = 0\nif utils.colors is not None:\n    for patch, color in zip(bplot['boxes'], [utils.colors['pD_3'], utils.colors['pD_4'], utils.colors['pD_3'], utils.colors['pD_4']]):\n        patch.set_facecolor(color)\n        if t < 2:\n            patch.set_alpha(0.4)\n        t = t + 1\n\n# rotate labels  \naxs.set_xticks(data_pos,data_labels, rotation=40)\n\nw1 = wilcoxon(data5, data6) \nprint(w1)\nplotting.plot_significance(pvalue = w1.pvalue, data1=data5, data2 = data6, data_pos = data_pos, \n                           ax=axs, lw=0.5, fontsize = label_size, y_bar = 1, y_asterix = 2)\n\npt = ttest_rel(data5, data6) \nprint(pt)\n\n\nfig_penalty"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"update_len = len(utils.update_ix)\nupdate_len"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"def calc_matrix_norm(M):\n    '''\n    calculates the frobenius norm squared of a 2-D matrix M\n    '''\n    M_norm = np.linalg.norm(M,'fro') #**2\n    return M_norm"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# def test_calc_matrix_norm():\n#     # using example from: https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html\n#     a = np.arange(9) - 4\n#     b = a.reshape((3, 3))\n#     ans = np.linalg.norm(b, 'fro')\n#     assert(calc_matrix_norm(b) == ans**2)\n\n#     # using definition from: https://mathworld.wolfram.com/FrobeniusNorm.html\n#     b_inner = [[b[i][j]**2 for j in range(b.shape[0])] for i in range(b.shape[1])]\n#     assert( (np.sqrt(np.sum(b_inner))**2) == calc_matrix_norm(b) )"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# b - decoder norms\n\nax = ax_dict['b']\nD_effort = np.zeros((utils.n_blocks, utils.n_keys, utils.n_conds, update_len - 1)) # 2 x 7 x 8 x 18\n# update_ix - 1 because the last update is not evenly spaced\n\n# calculate the decoder \"effort\" which is the decoder norm squared\nfor iK, key in enumerate(utils.keys):\n    for iC, cond in enumerate(conds):\n        # BLOCK 1\n        b = 0\n        # W1 = Ws_block1[key][iC][utils.update_ix] # so W1 = 19 x 2 x 64 \n        W1 = decoders[b, iK, iC]\n        # calculate each decoder norm per update\n        D_effort[b, iK, iC, :] = np.array([calc_matrix_norm(W1[ii]) for ii in range(update_len - 1)])\n        \n        # BLOCK 2\n        b = 1\n        # W2 = Ws_block2[key][iC][utils.update_ix] # W2 = 19 x 2 x 64\n        W2 = decoders[b, iK, iC]\n        # calculate each decoder norm per update\n        D_effort[b, iK, iC, :] = np.array([calc_matrix_norm(W2[ii]) for ii in range(update_len - 1)])    \n            \n# check the shape\nassert(D_effort.shape == (utils.n_blocks, utils.n_keys, utils.n_conds, update_len - 1))\n\n# check that all decoder norms were calculated\nassert(np.all(D_effort))\n\n# take the mean decoder norm per subject \nD_norm_pd3 = np.mean(D_effort[:, :, utils.pD_3], axis = (0, 2)) # so each subject has a D_norm_pd3 plot\nD_norm_pd4 = np.mean(D_effort[:, :, utils.pD_4], axis = (0, 2))\n\n# axis = 0\n# make sure the N's are correctly compared\nassert(D_norm_pd3.shape == (utils.n_keys, update_len-1))\nassert(D_norm_pd4.shape == (utils.n_keys, update_len-1))\n\n\n# take the median + interquartile distribution across subjects\n# NOTE: taking the first time index (1:) off b/c it's the initial decoder and is very small in comparison\n##  looks weird on the graph\nD_norm_pd3_25, D_norm_pd3_50, D_norm_pd3_75 = np.percentile(D_norm_pd3[:, 1:], \n                                                            [25, 50, 75] , axis=0)\nD_norm_pd4_25, D_norm_pd4_50, D_norm_pd4_75 = np.percentile(D_norm_pd4[:, 1:], \n                                                            [25, 50, 75] , axis=0)\n\n# x-axis for graphing\nxn = np.linspace(20, 300, len(D_norm_pd3_50))/60 # minutes\n\n\nax.fill_between(xn, D_norm_pd3_25, D_norm_pd3_75, \n                alpha=0.1, color = utils.colors['pD_3'], edgecolor = None)\nax.fill_between(xn, D_norm_pd4_25, D_norm_pd4_75, \n                alpha=0.1, color = utils.colors['pD_4'], edgecolor = None)\n\nax.plot(xn, D_norm_pd3_50, '-o', alpha=1, linewidth=1, markersize=1,\n        color = utils.colors['pD_3'], label = 'high $\\lambda$')#, \\lambda_D = 1e-3$')\n\nax.plot(xn, D_norm_pd4_50, '--o', alpha=1, linewidth=1, markersize=1, \n        color = utils.colors['pD_4'], label = 'low $\\lambda$') #, \\lambda_D = 1e-4$')\n\n\nax.legend(labelcolor='linecolor', handlelength=2, frameon=False,  loc='upper right', fontsize = label_size)\n\nfig_penalty"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"axs = ax_dict['c']\n\n# take mean across entire trial\n# D_effort already cuts out the last decoder update that is short\nD_norm_pd3_subj = np.mean(D_effort[:, :, utils.pD_3, :], axis = (0, 2, -1)) # so each subject has a D_norm_pd3 plot\nD_norm_pd4_subj = np.mean(D_effort[:, :, utils.pD_4, :], axis = (0, 2, -1))\nassert(D_norm_pd3_subj.shape == D_norm_pd4_subj.shape == (utils.n_keys, ))\n\ndata1 = np.ndarray.flatten(D_norm_pd3_subj)\ndata2 = np.ndarray.flatten(D_norm_pd4_subj)\n\n\ndata_groups = [data1, data2]\ndata_labels = ['high', 'low',]\ndata_pos = [0, 0.4]\nbplot = axs.boxplot(data_groups, \n                    showfliers=False,\n                    patch_artist=True,\n                    positions=data_pos,\n                    widths = 0.3,\n                    boxprops=dict(edgecolor=\"none\"),\n                     medianprops=dict(color='k', lw=1))\n\n\nt = 0\nif utils.colors is not None:\n    for patch, color in zip(bplot['boxes'], [utils.colors['pD_3'], utils.colors['pD_4']]):\n        patch.set_facecolor(color)\n\n\n# rotate labels  \naxs.set_xticks(data_pos,data_labels, rotation=40)\n\nw1 = wilcoxon(data1, data2) \nprint(w1)\nplotting.plot_significance(pvalue = w1.pvalue, data1=data1, data2 = data2, data_pos = data_pos[:2], \n                           ax=axs, lw=0.5, fontsize = 10, y_bar = 0.3, y_asterix = 0.5)\n\npt = ttest_rel(data1, data2) \nprint(pt)\n\n#w2 = wilcoxon(data3, data4) \n#print(w2)\n\n#plotting.plot_significance(pvalue = w2.pvalue, data1=data3, data2 = data4, data_pos = data_pos[-2:], \n                           \n\nfig_penalty"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"enc_linear = encoder[:, :, :, :, :, :-1]\nassert(enc_linear.shape == (utils.n_blocks, utils.n_keys, utils.n_conds, update_len - 2, utils.n_ch, 8))"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# b - decoder norms\n\nax = ax_dict['d']\nE_effort = np.zeros((utils.n_blocks, utils.n_keys, utils.n_conds, update_len - 2)) # 2 x 7 x 8 x 18\n# update_ix - 1 because the last update is not evenly spaced\n\nenc_linear = encoder[:, :, :, :, :, :-1]\n# calculate the decoder \"effort\" which is the decoder norm squared\nfor iK, key in enumerate(utils.keys):\n    for iB in range(utils.n_blocks):\n        for iC, cond in enumerate(conds):\n            \n            enc = enc_linear[iB, iK, iC]# so E1 = num updates x 64 x 8\n            E_norm = np.array([calc_matrix_norm(enc[ii, :, : ]) for ii in range(update_len - 2)])\n            assert(E_norm.shape == (update_len - 2, ))\n            \n            E_effort[iB, iK, iC, :] = E_norm  \n                \n# check the shape\nassert(E_effort.shape == (utils.n_blocks, utils.n_keys, utils.n_conds, update_len - 2))\n\n# check that all decoder norms were calculated\nassert(np.all(E_effort))\n\n# take the mean per subject and then interquartile across subjects\nE_norm_pd3 = np.mean(E_effort[:, :, utils.pD_3], axis = (0, 2)) # so each subject has a D_norm_pd3 plot\nE_norm_pd4 = np.mean(E_effort[:, :, utils.pD_4], axis = (0, 2))\n\n# axis = 0\n# make sure the N's are correctly compared\nassert(E_norm_pd3.shape == (utils.n_keys, update_len-2))\nassert(E_norm_pd4.shape == (utils.n_keys, update_len-2))\n\n\nE_norm_pd3_25, E_norm_pd3_50, E_norm_pd3_75 = np.percentile(E_norm_pd3, [25, 50, 75] , axis=0)\nE_norm_pd4_25, E_norm_pd4_50, E_norm_pd4_75 = np.percentile(E_norm_pd4, [25, 50, 75] , axis=0)\n\n\nxn = np.linspace(20, 300, len(E_norm_pd3_50))/60 # minutes\nax.fill_between(xn, E_norm_pd3_25, E_norm_pd3_75, \n                alpha=0.1, color = utils.colors['pD_3'], edgecolor = None)\nax.fill_between(xn, E_norm_pd4_25, E_norm_pd4_75, \n                alpha=0.1, color = utils.colors['pD_4'], edgecolor = None)\n\nax.plot(xn, E_norm_pd3_50, '-o', alpha=1, linewidth=1, markersize=1,\n        color = utils.colors['pD_3'], label = 'high $\\lambda$')#, \\lambda_D = 1e-3$')\n\nax.plot(xn, E_norm_pd4_50, '--o', alpha=1, linewidth=1, markersize=1, \n        color = utils.colors['pD_4'], label = 'low $\\lambda$') #, \\lambda_D = 1e-4$')\n\n\nax.legend(labelcolor='linecolor', handlelength=2, frameon=False,  loc='upper right', fontsize = label_size)\n\nax.set_ylim(0, 8)\nfig_penalty"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"axs = ax_dict['e']\n\n# pd3 =  10^-3 > 10^-4 ; pd3 = high, pd4 = low\n\n# take the median per subject for each condition\nE_norm_pd3_subj = np.mean(E_effort[:, :, utils.pD_3, :], axis = (0, 2, -1)) # so each subject has a D_norm_pd3 plot\nE_norm_pd4_subj = np.mean(E_effort[:, :, utils.pD_4, :], axis = (0, 2, -1))\nassert(E_norm_pd3_subj.shape == E_norm_pd4_subj.shape == (utils.n_keys, ))\n\ndata1 = np.ndarray.flatten(E_norm_pd3_subj) # high\ndata2 = np.ndarray.flatten(E_norm_pd4_subj) # low\n\n\nprint(E_norm_pd3_subj - E_norm_pd4_subj)\n\ndata_groups = [data1, data2]\ndata_labels = ['high', 'low',]\ndata_pos = [0, 0.4]\nbplot = axs.boxplot(data_groups, \n                    showfliers=False,\n                    patch_artist=True,\n                    positions=data_pos,\n                    widths = 0.3,\n                    boxprops=dict(edgecolor=\"none\"),\n                    medianprops=dict(color='k', lw=1))\n\n\nt = 0\nif utils.colors is not None:\n    for patch, color in zip(bplot['boxes'], [utils.colors['pD_3'], utils.colors['pD_4']]):\n        patch.set_facecolor(color)\n\n\n# rotate labels  \naxs.set_xticks(data_pos,data_labels, rotation=40)\n\nw1 = wilcoxon(data1, data2) \nprint(w1)\nplotting.plot_significance(pvalue = w1.pvalue, data1=data1, data2 = data2, data_pos = data_pos[:2], \n                           ax=axs, lw=0.5, fontsize = 10, y_bar = 0.5, y_asterix = 1)\n\n\npt = ttest_rel(data1, data2) \nprint(pt)\n\n\naxs.set_ylim(0, 20)\nw2 = wilcoxon(data1, data2, alternative='greater') \nprint(w2)\n\n\n#plotting.plot_significance(pvalue = w2.pvalue, data1=data3, data2 = data4, data_pos = data_pos[-2:], \n                           \n\nfig_penalty"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# check data\nfor iK, key in enumerate(keys):\n    for iC, cond in enumerate(conds):\n        # block 1\n        assert(np.all(dec_vels[0, iK, iC] == dec_vels_block1[key][iC, :, :]))\n\n        # block 2\n        assert(np.all(dec_vels[1, iK, iC] == dec_vels_block2[key][iC, :, :]))"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"dec_vels.shape"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"20770/5 "},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"last_min = int(utils.min_time/5)\nlast_min"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# f\naxs = ax_dict['g']\n\n# mean across entire trial\ndvels_pd3_subj = np.mean(np.linalg.norm(dec_vels[:, :, utils.pD_3, :] * (utils.x_cm_to_au,utils.y_cm_to_au), \n                                    ord = 2, axis = -1), axis = (0, 2, 3)) \nassert(dvels_pd3_subj.shape == (utils.n_keys, ))\n\n\ndvels_pd4_subj = np.mean(np.linalg.norm(dec_vels[:, :, utils.pD_4, :] * (utils.x_cm_to_au,utils.y_cm_to_au),\n                                    ord = 2,axis = -1), axis = (0, 2, 3))\n\nassert(dvels_pd4_subj.shape == (utils.n_keys, ))\n\ndata1 = np.ndarray.flatten(dvels_pd3_subj)\ndata2 = np.ndarray.flatten(dvels_pd4_subj)\n\n\ndata_groups = [data1, data2]\ndata_labels = ['high', 'low',]\ndata_pos = [0, 0.4]\nbplot = axs.boxplot(data_groups, \n                    showfliers=False,\n                    patch_artist=True,\n                    positions=data_pos,\n                    widths = 0.3,\n                    boxprops=dict(edgecolor=\"none\"),\n                    medianprops=dict(color='k', lw=1))\n\n\nt = 0\nif utils.colors is not None:\n    for patch, color in zip(bplot['boxes'], [utils.colors['pD_3'], utils.colors['pD_4']]):\n        patch.set_facecolor(color)\n\n\n# rotate labels  \naxs.set_xticks(data_pos,data_labels, rotation=40)\n\nw1 = wilcoxon(data1, data2) \nprint(w1)\nplotting.plot_significance(pvalue = w1.pvalue, data1=data1, data2 = data2, data_pos = data_pos[:2], \n                           ax=axs, lw=0.5, fontsize = 10, y_bar =-4, y_asterix =-4)\n\npt = ttest_rel(data1, data2) \nprint(pt)\n\n# axs.set_ylim(11, 16)\n\n\nfig_penalty"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"dvels_pd3 = np.mean(np.linalg.norm(dec_vels[:, :, utils.pD_3] * (utils.x_cm_to_au,utils.y_cm_to_au),\n                                    ord = 2, axis = -1), axis = (0, 2))\ndvels_pd4 = np.mean(np.linalg.norm(dec_vels[:, :, utils.pD_4] * (utils.x_cm_to_au,utils.y_cm_to_au),\n                                    ord = 2,axis = -1), axis = (0, 2))\n\n\ndvels_pd3_25, dvels_pd3_50, dvels_pd3_75 = np.percentile(dvels_pd3, [25, 50, 75] , axis=0)\ndvels_pd4_25, dvels_pd4_50, dvels_pd4_75 = np.percentile(dvels_pd4, [25, 50, 75] , axis=0)\n\n# fig, ax = plt.subplots(1, 1, figsize=(2, 2))\n\n# ax = ax_dict2['a']\nax = ax_dict['f']\nkernal_size = int((utils.min_time)/300 * 10) # in seconds\nplotting.plot_smooth_time_domain(np.linspace(0, 5, utils.min_time), dvels_pd3, data_len=utils.n_keys, \n                                 axis=0, kernal_size=kernal_size,ax=ax, lw =1, color = utils.colors['pD_3'], remove_axes=False)\nplotting.plot_smooth_time_domain(np.linspace(0, 5, utils.min_time), dvels_pd4, data_len=utils.n_keys, \n                                 axis=0, kernal_size=kernal_size,ax=ax, lw =1, color = utils.colors['pD_4'], remove_axes=False, ls = '--')\n\n# fig_vel2\nfig_penalty"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"from matplotlib import cm\n# Function to determine color based on slope\ndef get_color(slope, cmap):\n    norm = plt.Normalize(-40, 20)  # Assuming slopes range from -1 to 1\n    # slope = abs(slope)\n    return cmap(norm(slope))"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"dvels_pd3.shape"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# pd3 = high\n# pd4 = low\nax = ax_dict['h']\n\nax.xaxis.set_major_locator(ticker.MultipleLocator(base=3))\nax.xaxis.set_minor_locator(ticker.MultipleLocator(base=1))\n\n\ncmap = cm.get_cmap('Greys')  # You can choose any colormap\n\n\nfor iK in range(utils.n_keys):\n    x2 = E_norm_pd3_subj[iK] # expect higher norm\n    y2 = dvels_pd3_subj[iK] # expect lower velocity\n\n    x1 = E_norm_pd4_subj[iK] # low, expect lower norm\n    y1 = dvels_pd4_subj[iK] # low, expect higher velocity\n    slope = (y2 - y1)/(x2 - x1)\n    print(keys[iK])\n    print(slope)\n\n    ax.scatter(x1 - x2, y1 - y2, color = 'black', s = 8)\n\n\nax.set_xlabel(\"Change in E $|E_{low}| - |E_{high}|$\")\nax.set_ylabel(\"Change in v $v_{low} - v_{high}$\")\n\nax.vlines(x=0, ymin=0, ymax=5, color = 'gray', ls= '--')\nax.set_ylim(-.5, 5)\n\n\nfig_penalty"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"image_format = 'pdf' # e.g .png, .svg, etc.\nimage_name = 'fig5-penalty-effect-cm.pdf'\nPATH = '/results/'\nfig_penalty.savefig(PATH + image_name, format=image_format, dpi=300)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"analysis_env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":2}